{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85b26910-1a58-444d-9120-37fff69d4bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Run DQX Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9274bb5-90e8-45d3-82e8-dff980a0a574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Cell 1: Install DQX Package (if your cluster image doesn't already include it) ===\n",
    "%pip install databricks-labs-dqx==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f7b6c39-949b-41bd-809e-a70e40cce00d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === Cell 2: Restart Python to pick up libs (Databricks convention) ===\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d132b365-9402-4fe2-9a9e-a7995ede0e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "import yaml\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.labs.dqx.config import TableChecksStorageConfig\n",
    "from pyspark.sql import SparkSession, DataFrame, functions as F, types as T\n",
    "from utils.color import Color\n",
    "\n",
    "# =========================\n",
    "# Schema for DQX checks log\n",
    "# =========================\n",
    "DQX_CHECKS_LOG_SCHEMA = T.StructType([\n",
    "    T.StructField(\"result_id\",       T.StringType(),  False),\n",
    "    T.StructField(\"rule_id\",         T.StringType(),  False),\n",
    "    T.StructField(\"source_table\",    T.StringType(),  False),\n",
    "    T.StructField(\"run_config_name\", T.StringType(),  False),\n",
    "    T.StructField(\"severity\",        T.StringType(),  False),\n",
    "    T.StructField(\"name\",            T.StringType(),  True),\n",
    "    T.StructField(\"message\",         T.StringType(),  True),\n",
    "    T.StructField(\"columns\",         T.ArrayType(T.StringType()), True),\n",
    "    T.StructField(\"filter\",          T.StringType(),  True),\n",
    "    T.StructField(\"function\",        T.StringType(),  True),\n",
    "    T.StructField(\"run_time\",        T.TimestampType(), True),\n",
    "    T.StructField(\"user_metadata\",   T.MapType(T.StringType(), T.StringType()), True),\n",
    "    T.StructField(\"created_by\",      T.StringType(),  False),\n",
    "    T.StructField(\"created_at\",      T.TimestampType(), False),\n",
    "    T.StructField(\"updated_by\",      T.StringType(),  True),\n",
    "    T.StructField(\"updated_at\",      T.TimestampType(), True)\n",
    "])\n",
    "\n",
    "def _get(obj, attr, default=None):\n",
    "    \"\"\"Works for both dicts and DQX model objects.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return obj.get(attr, default)\n",
    "    return getattr(obj, attr, default)\n",
    "\n",
    "class DQXCheckRunner:\n",
    "    def __init__(self, spark: SparkSession, engine: DQEngine, debug: bool = True):\n",
    "        self.spark = spark\n",
    "        self.engine = engine\n",
    "        self.debug = debug\n",
    "\n",
    "    # --- Printing helpers ---\n",
    "    def print_info(self, msg: str) -> None:\n",
    "        print(f\"{Color.b}{Color.aqua_blue}{msg}{Color.r}\")\n",
    "\n",
    "    def print_warn(self, msg: str) -> None:\n",
    "        print(f\"{Color.b}{Color.yellow}{msg}{Color.r}\")\n",
    "\n",
    "    def print_error(self, msg: str) -> None:\n",
    "        print(f\"{Color.b}{Color.candy_red}{msg}{Color.r}\")\n",
    "\n",
    "    # --- File/YAML helpers ---\n",
    "    def read_yaml(self, path: str) -> Dict[str, Any]:\n",
    "        if path.startswith(\"dbfs:/\"):\n",
    "            path = path.replace(\"dbfs:/\", \"/dbfs/\")\n",
    "        with open(path, \"r\") as fh:\n",
    "            return yaml.safe_load(fh) or {}\n",
    "\n",
    "    # --- Table helpers ---\n",
    "    def ensure_table_with_schema(self, full_name: str) -> None:\n",
    "        if not self.spark.catalog.tableExists(full_name):\n",
    "            cat, sch, _ = full_name.split(\".\")\n",
    "            self.spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{cat}`.`{sch}`\")\n",
    "            self.spark.createDataFrame([], DQX_CHECKS_LOG_SCHEMA) \\\n",
    "                .write.format(\"delta\").mode(\"overwrite\").saveAsTable(full_name)\n",
    "\n",
    "    def load_checks_for_run_config(self, checks_table: str, rc_name: str) -> List[dict]:\n",
    "        return self.engine.load_checks(\n",
    "            config=TableChecksStorageConfig(location=checks_table, run_config_name=rc_name)\n",
    "        )\n",
    "\n",
    "    def group_checks_by_table(self, checks: List[dict]) -> Dict[str, List[dict]]:\n",
    "        \"\"\"\n",
    "        Robustly pull table name from either dict or DQX model:\n",
    "        prefer 'table_name', else 'table'.\n",
    "        \"\"\"\n",
    "        out: Dict[str, List[dict]] = {}\n",
    "        for c in checks:\n",
    "            tbl = _get(c, \"table_name\") or _get(c, \"table\")\n",
    "            if tbl:\n",
    "                out.setdefault(tbl, []).append(c)\n",
    "        return out\n",
    "\n",
    "    def _summarize_hits(self, annotated: DataFrame) -> Tuple[int, int]:\n",
    "        if \"_error\" not in annotated.columns and \"_warning\" not in annotated.columns:\n",
    "            return (0, 0)\n",
    "        agg = annotated.select(\n",
    "            F.size(F.col(\"_error\")).alias(\"e_sz\"),\n",
    "            F.size(F.col(\"_warning\")).alias(\"w_sz\")\n",
    "        ).agg(\n",
    "            F.coalesce(F.sum(\"e_sz\"), F.lit(0)).alias(\"errors\"),\n",
    "            F.coalesce(F.sum(\"w_sz\"), F.lit(0)).alias(\"warnings\")\n",
    "        ).collect()[0]\n",
    "        return int(agg[\"errors\"]), int(agg[\"warnings\"])\n",
    "\n",
    "    def _with_rule_id(\n",
    "        self,\n",
    "        exploded: DataFrame,\n",
    "        source_table: str,\n",
    "        run_config_name: str\n",
    "    ) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Attach a deterministic rule_id so we don't have to join back to the config:\n",
    "        md5(table_name || run_config_name || name)\n",
    "        \"\"\"\n",
    "        return exploded.withColumn(\n",
    "            \"rule_id\",\n",
    "            F.md5(F.concat_ws(\"||\",\n",
    "                              F.lit(source_table),\n",
    "                              F.lit(run_config_name),\n",
    "                              F.coalesce(F.col(\"name\"), F.lit(\"\"))))\n",
    "        )\n",
    "\n",
    "    def explode_result_array(\n",
    "        self,\n",
    "        df: DataFrame,\n",
    "        array_col: str,\n",
    "        severity_literal: str,\n",
    "        source_table: str,\n",
    "        run_config_name: str,\n",
    "        created_by: str\n",
    "    ) -> DataFrame:\n",
    "        if array_col not in df.columns:\n",
    "            return self.spark.createDataFrame([], DQX_CHECKS_LOG_SCHEMA)\n",
    "\n",
    "        exploded = df.select(F.explode_outer(F.col(array_col)).alias(\"r\")).select(\"r.*\")\n",
    "        if exploded.rdd.isEmpty():\n",
    "            return self.spark.createDataFrame([], DQX_CHECKS_LOG_SCHEMA)\n",
    "\n",
    "        exploded = self._with_rule_id(exploded, source_table, run_config_name)\n",
    "\n",
    "        # select in schema order\n",
    "        cols_in_order = [f.name for f in DQX_CHECKS_LOG_SCHEMA.fields]\n",
    "        return (\n",
    "            exploded\n",
    "            .withColumn(\"result_id\",       F.expr(\"uuid()\"))\n",
    "            .withColumn(\"source_table\",    F.lit(source_table))\n",
    "            .withColumn(\"run_config_name\", F.lit(run_config_name))\n",
    "            .withColumn(\"severity\",        F.lit(severity_literal))\n",
    "            .withColumn(\"created_by\",      F.lit(created_by))\n",
    "            .withColumn(\"created_at\",      F.current_timestamp())\n",
    "            .withColumn(\"updated_by\",      F.lit(None).cast(T.StringType()))\n",
    "            .withColumn(\"updated_at\",      F.lit(None).cast(T.TimestampType()))\n",
    "            .select(*cols_in_order)\n",
    "        )\n",
    "\n",
    "    def apply_checks_for_table(\n",
    "        self, src_table: str, tbl_checks: List[dict]\n",
    "    ) -> Optional[DataFrame]:\n",
    "        try:\n",
    "            df_src = self.spark.read.table(src_table)\n",
    "        except Exception as e:\n",
    "            self.print_error(f\"Cannot read {src_table}: {e}\")\n",
    "            return None\n",
    "        try:\n",
    "            # Adds _error / _warning arrays per row (LOG-ONLY path)\n",
    "            return self.engine.apply_checks_by_metadata(df_src, tbl_checks)\n",
    "        except Exception as e:\n",
    "            self.print_error(f\"apply_checks_by_metadata failed for {src_table}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def write_hits(\n",
    "        self, out_df: DataFrame, results_table: str, mode: str, options: Dict[str, str]\n",
    "    ) -> int:\n",
    "        if out_df.rdd.isEmpty():\n",
    "            self.print_info(\"No rows to write.\")\n",
    "            return 0\n",
    "        # enforce schema/order\n",
    "        out_df = out_df.select([f.name for f in DQX_CHECKS_LOG_SCHEMA.fields])\n",
    "        written = out_df.count()\n",
    "        out_df.write.format(\"delta\").mode(mode).options(**options).saveAsTable(results_table)\n",
    "        return written\n",
    "\n",
    "    def apply_for_run_config(\n",
    "        self,\n",
    "        checks_table: str,\n",
    "        rc_name: str,\n",
    "        results_table: str,\n",
    "        write_mode: str,\n",
    "        write_options: Dict[str, str],\n",
    "        created_by: str\n",
    "    ) -> int:\n",
    "        self.print_info(f\"RUN-CONFIG: {rc_name}\")\n",
    "\n",
    "        # Load checks from the Delta table (one row = one rule to run)\n",
    "        try:\n",
    "            checks = self.load_checks_for_run_config(checks_table, rc_name)\n",
    "        except Exception as e:\n",
    "            self.print_error(f\"Failed to load checks for {rc_name}: {e}\")\n",
    "            return 0\n",
    "\n",
    "        if not checks:\n",
    "            self.print_warn(f\"No checks found for run-config '{rc_name}'.\")\n",
    "            return 0\n",
    "\n",
    "        status = DQEngine.validate_checks(checks)\n",
    "        if getattr(status, \"has_errors\", False):\n",
    "            self.print_error(f\"Invalid checks for {rc_name}: {status}\")\n",
    "            return 0\n",
    "\n",
    "        by_table = self.group_checks_by_table(checks)\n",
    "        checks_loaded = len(checks)\n",
    "        tables_targeted = len(by_table)\n",
    "        self.print_info(f\"Loaded {checks_loaded} checks across {tables_targeted} table(s).\")\n",
    "\n",
    "        if tables_targeted:\n",
    "            self.print_info(\"Target tables: \" + \", \".join(sorted(by_table.keys())))\n",
    "\n",
    "        # Ensure sink exists\n",
    "        self.ensure_table_with_schema(results_table)\n",
    "\n",
    "        # Per-run-config counters\n",
    "        rc_total_written = 0\n",
    "        rc_total_err = 0\n",
    "        rc_total_warn = 0\n",
    "\n",
    "        # Execute per table\n",
    "        for src_table, tbl_checks in by_table.items():\n",
    "            self.print_info(f\"Table: {src_table} | checks to run: {len(tbl_checks)}\")\n",
    "            annotated = self.apply_checks_for_table(src_table, tbl_checks)\n",
    "            if annotated is None:\n",
    "                continue\n",
    "\n",
    "            e_cnt, w_cnt = self._summarize_hits(annotated)\n",
    "            self.print_info(f\"  - Raw per-row arrays: errors={e_cnt}, warnings={w_cnt}\")\n",
    "\n",
    "            errors_df   = self.explode_result_array(annotated, \"_error\",   \"error\",   src_table, rc_name, created_by)\n",
    "            warnings_df = self.explode_result_array(annotated, \"_warning\", \"warning\", src_table, rc_name, created_by)\n",
    "            out_df = errors_df.unionByName(warnings_df, allowMissingColumns=True)\n",
    "\n",
    "            if out_df.rdd.isEmpty():\n",
    "                self.print_info(\"  - No error/warning hits after explode.\")\n",
    "                continue\n",
    "\n",
    "            sev_counts = {r[\"severity\"]: r[\"count\"] for r in out_df.groupBy(\"severity\").count().collect()}\n",
    "            rc_total_err  += int(sev_counts.get(\"error\", 0))\n",
    "            rc_total_warn += int(sev_counts.get(\"warning\", 0))\n",
    "\n",
    "            if self.debug:\n",
    "                self.print_info(\"  - Top rules by hit count:\")\n",
    "                out_df.groupBy(\"rule_id\", \"name\", \"severity\").count().orderBy(F.desc(\"count\")).show(10, truncate=False)\n",
    "\n",
    "            written = self.write_hits(out_df, results_table, write_mode, write_options)\n",
    "            rc_total_written += written\n",
    "            self.print_info(f\"  - Written rows for {src_table}: {written}\")\n",
    "\n",
    "        # Per-run-config summary\n",
    "        self.print_info(\n",
    "            f\"SUMMARY [{rc_name}] -> checks={checks_loaded}, tables={tables_targeted}, \"\n",
    "            f\"hits_err={rc_total_err}, hits_warn={rc_total_warn}, written_rows={rc_total_written}\"\n",
    "        )\n",
    "\n",
    "        return rc_total_written\n",
    "\n",
    "\n",
    "def main(\n",
    "    dqx_config_yaml: str = \"resources/dqx_config.yaml\",\n",
    "    results_table_override: Optional[str] = None,\n",
    "    created_by: str = \"AdminUser\",\n",
    "    debug: bool = True\n",
    ") -> None:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    engine = DQEngine(WorkspaceClient())\n",
    "    runner = DQXCheckRunner(spark, engine, debug=debug)\n",
    "\n",
    "    cfg = runner.read_yaml(dqx_config_yaml)\n",
    "    checks_table = cfg[\"dqx_checks_config_table_name\"]\n",
    "    global_results_table = results_table_override or cfg[\"dqx_checks_log_table_name\"]\n",
    "\n",
    "    rc_map: Dict[str, Any] = cfg.get(\"run_config_name\", {}) or {}\n",
    "    if not rc_map:\n",
    "        raise ValueError(\"No run_config_name in config.\")\n",
    "\n",
    "    grand_total = 0\n",
    "    for rc_name, rc_cfg in rc_map.items():\n",
    "        if rc_name.lower() == \"none\":\n",
    "            # ignore the placeholder profile entirely\n",
    "            continue\n",
    "\n",
    "        out_cfg = (rc_cfg or {}).get(\"output_config\", {}) or {}\n",
    "        out_mode = out_cfg.get(\"mode\", \"overwrite\")\n",
    "        out_options = out_cfg.get(\"options\", {}) or {}\n",
    "\n",
    "        written = runner.apply_for_run_config(\n",
    "            checks_table=checks_table,\n",
    "            rc_name=rc_name,\n",
    "            results_table=global_results_table,\n",
    "            write_mode=out_mode,\n",
    "            write_options=out_options,\n",
    "            created_by=created_by\n",
    "        )\n",
    "        grand_total += written\n",
    "\n",
    "    runner.print_info(f\"TOTAL rows written across all run-configs: {grand_total}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0c7afdb-7747-43fc-bbec-f941668a5b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from collections import defaultdict\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "yaml_path = \"resources/dqx_checks_config/two_rules_test.yaml\"\n",
    "\n",
    "# 1) Load YAML\n",
    "with open(yaml_path, \"r\") as fh:\n",
    "    rules = yaml.safe_load(fh) or []\n",
    "if isinstance(rules, dict):\n",
    "    rules = [rules]\n",
    "\n",
    "# 2) Group by table\n",
    "by_table = defaultdict(list)\n",
    "for r in rules:\n",
    "    t = r.get(\"table_name\")\n",
    "    if t:\n",
    "        by_table[t].append(r)\n",
    "\n",
    "print(f\"Loaded {sum(len(v) for v in by_table.values())} rule(s) across {len(by_table)} table(s): {list(by_table.keys())}\")\n",
    "\n",
    "engine = DQEngine(WorkspaceClient())\n",
    "\n",
    "# 3) Apply per table\n",
    "for table, tbl_rules in by_table.items():\n",
    "    print(f\"\\n=== Applying {len(tbl_rules)} rule(s) to {table} ===\")\n",
    "    df = spark.table(table)\n",
    "\n",
    "    annotated = engine.apply_checks_by_metadata(df, tbl_rules)\n",
    "\n",
    "    # DQX may use _error/_warning or _errors/_warnings depending on version\n",
    "    err_col = \"_errors\"  if \"_errors\"  in annotated.columns else \"_error\"\n",
    "    wrn_col = \"_warnings\" if \"_warnings\" in annotated.columns else \"_warning\"\n",
    "\n",
    "    # Summary\n",
    "    agg = (\n",
    "        annotated.select(\n",
    "            F.size(F.col(err_col)).alias(\"e_sz\"),\n",
    "            F.size(F.col(wrn_col)).alias(\"w_sz\"),\n",
    "        )\n",
    "        .agg(\n",
    "            F.coalesce(F.sum(\"e_sz\"), F.lit(0)).alias(\"errors\"),\n",
    "            F.coalesce(F.sum(\"w_sz\"), F.lit(0)).alias(\"warnings\"),\n",
    "        )\n",
    "        .collect()[0]\n",
    "    )\n",
    "    print(f\"Hit summary -> errors={int(agg['errors'])}, warnings={int(agg['warnings'])}\")\n",
    "\n",
    "    # Keep only rows that actually have hits\n",
    "    hits_only = annotated.filter(\n",
    "        (F.col(err_col).isNotNull() & (F.size(F.col(err_col)) > 0)) |\n",
    "        (F.col(wrn_col).isNotNull() & (F.size(F.col(wrn_col)) > 0))\n",
    "    )\n",
    "\n",
    "    # Explode per array (no _outer), then union; drop all-null just in case\n",
    "    errors = (\n",
    "        hits_only.filter(F.size(F.col(err_col)) > 0)\n",
    "        .select(F.explode(F.col(err_col)).alias(\"r\"))\n",
    "        .select(\"r.*\")\n",
    "    )\n",
    "    warnings = (\n",
    "        hits_only.filter(F.size(F.col(wrn_col)) > 0)\n",
    "        .select(F.explode(F.col(wrn_col)).alias(\"r\"))\n",
    "        .select(\"r.*\")\n",
    "    )\n",
    "    hits = errors.unionByName(warnings, allowMissingColumns=True).na.drop(\"all\")\n",
    "\n",
    "    print(\"\\nSummary by rule:\")\n",
    "    hits.groupBy(\"name\", \"function\").count().orderBy(F.desc(\"count\")).show(truncate=False)\n",
    "\n",
    "    print(\"\\nViolations (one row per hit):\")\n",
    "    try:\n",
    "        display(hits.select(\"name\", \"message\", \"columns\", \"filter\", \"function\", \"run_time\", \"user_metadata\"))\n",
    "    except NameError:\n",
    "        hits.select(\"name\", \"message\", \"columns\", \"filter\", \"function\", \"run_time\", \"user_metadata\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fc9748f-4f9e-4e10-95e4-96d9fde21968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hits.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89bee027-4577-4657-98e0-0b47586c0aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_run_dqx_checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
