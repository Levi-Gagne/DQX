{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5eee61a2-011c-4ef8-ba15-23a1feef850c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DQX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaaa1444-dea5-4903-8a9a-a920c9bcc371",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Kim's Notebook"
    }
   },
   "outputs": [],
   "source": [
    "https://adb-5943863453538272.12.azuredatabricks.net/editor/notebooks/4441860942440814?o=5943863453538272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db71ab93-6f9f-42c4-a5cf-aab8380cacd3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DQX Dashboard"
    }
   },
   "outputs": [],
   "source": [
    "databricks labs dqx open-dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b21625d-5222-462d-8790-7313492cd62b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bab9e4c-dacd-491f-a3ce-96cceed0fa5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Built‑in DQX quality rule definitions\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "ROW_LEVEL_FUNCTIONS = {\n",
    "    \"is_not_null\": {\"args\": [\"column\"], \"optional\": []},\n",
    "    \"is_not_empty\": {\"args\": [\"column\"], \"optional\": []},\n",
    "    \"is_not_null_and_not_empty\": {\"args\": [\"column\"], \"optional\": [\"trim_strings\"]},\n",
    "    \"is_in_list\": {\"args\": [\"column\", \"allowed\"], \"optional\": []},\n",
    "    \"is_not_null_and_is_in_list\": {\"args\": [\"column\", \"allowed\"], \"optional\": []},\n",
    "    \"is_not_null_and_not_empty_array\": {\"args\": [\"column\"], \"optional\": []},\n",
    "    \"is_in_range\": {\"args\": [\"column\", \"min_limit\", \"max_limit\"], \"optional\": []},\n",
    "    \"is_not_in_range\": {\"args\": [\"column\", \"min_limit\", \"max_limit\"], \"optional\": []},\n",
    "    \"is_not_less_than\": {\"args\": [\"column\", \"limit\"], \"optional\": []},\n",
    "    \"is_not_greater_than\": {\"args\": [\"column\", \"limit\"], \"optional\": []},\n",
    "    \"is_valid_date\": {\"args\": [\"column\"], \"optional\": [\"date_format\"]},\n",
    "    \"is_valid_timestamp\": {\"args\": [\"column\"], \"optional\": [\"timestamp_format\"]},\n",
    "    \"is_not_in_future\": {\"args\": [\"column\", \"offset\"], \"optional\": [\"curr_timestamp\"]},\n",
    "    \"is_not_in_near_future\": {\"args\": [\"column\", \"offset\"], \"optional\": [\"curr_timestamp\"]},\n",
    "    \"is_older_than_n_days\": {\"args\": [\"column\", \"days\"], \"optional\": [\"curr_date\", \"negate\"]},\n",
    "    \"is_older_than_col2_for_n_days\": {\"args\": [\"column1\", \"column2\", \"days\"], \"optional\": [\"negate\"]},\n",
    "    \"regex_match\": {\"args\": [\"column\", \"regex\"], \"optional\": [\"negate\"]},\n",
    "    \"is_valid_ipv4_address\": {\"args\": [\"column\"], \"optional\": []},\n",
    "    \"is_ipv4_address_in_cidr\": {\"args\": [\"column\", \"cidr_block\"], \"optional\": []},\n",
    "    \"sql_expression\": {\n",
    "        \"args\": [\"expression\"],\n",
    "        \"optional\": [\"msg\", \"name\", \"negate\", \"columns\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASET_LEVEL_FUNCTIONS = {\n",
    "    \"is_unique\": {\n",
    "        \"args\": [\"columns\"],\n",
    "        \"optional\": [\"nulls_distinct\"],\n",
    "    },\n",
    "    \"is_aggr_not_greater_than\": {\n",
    "        \"args\": [\"limit\"],\n",
    "        \"optional\": [\"column\", \"aggr_type\", \"group_by\"],\n",
    "    },\n",
    "    \"is_aggr_not_less_than\": {\n",
    "        \"args\": [\"limit\"],\n",
    "        \"optional\": [\"column\", \"aggr_type\", \"group_by\"],\n",
    "    },\n",
    "    \"is_aggr_equal\": {\n",
    "        \"args\": [\"limit\"],\n",
    "        \"optional\": [\"column\", \"aggr_type\", \"group_by\"],\n",
    "    },\n",
    "    \"is_aggr_not_equal\": {\n",
    "        \"args\": [\"limit\"],\n",
    "        \"optional\": [\"column\", \"aggr_type\", \"group_by\"],\n",
    "    },\n",
    "    \"foreign_key\": {\n",
    "        \"args\": [\"columns\", \"ref_columns\"],\n",
    "        \"optional\": [\"ref_df_name\", \"ref_table\", \"negate\"],\n",
    "    },\n",
    "    \"sql_query\": {\n",
    "        \"args\": [\"query\", \"merge_columns\", \"condition_column\"],\n",
    "        \"optional\": [\"input_placeholder\", \"msg\", \"name\", \"negate\"],\n",
    "    },\n",
    "    \"compare_datasets\": {\n",
    "        \"args\": [\"columns\", \"ref_columns\"],\n",
    "        \"optional\": [\"exclude_columns\", \"ref_df_name\", \"ref_table\", \"check_missing_records\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "CRITICALITY_VALUES = {\n",
    "    \"error\": \"record goes only into the bad/quarantine DataFrame\",\n",
    "    \"warn\": \"record goes into both good and bad DataFrames\",\n",
    "}\n",
    "\n",
    "NEGATE_VALUES = [True, False]\n",
    "\n",
    "REGEX_PARAMETER = {\n",
    "    \"key\": \"regex\",\n",
    "    \"type\": \"str\",\n",
    "    \"description\": \"Regular expression used by regex_match to evaluate values\",\n",
    "    \"used_in\": [\"regex_match\"],\n",
    "}\n",
    "\n",
    "RULE_LEVEL = [\"row\", \"aggregate\"]\n",
    "FUNCTION_TYPE = [\"built_in\", \"sql_expression\", \"custom\"]\n",
    "\n",
    "CHECK_METADATA_FIELDS = {\n",
    "    \"criticality\": {\"type\": \"str\", \"allowed_values\": list(CRITICALITY_VALUES.keys())},\n",
    "    \"check\": {\n",
    "        \"function\": {\"type\": \"str\"},\n",
    "        \"arguments\": {\"type\": \"dict\"},\n",
    "        \"for_each_column\": {\"type\": \"list[str]\", \"optional\": True},\n",
    "    },\n",
    "    \"name\": {\"type\": \"str\", \"optional\": True},\n",
    "    \"filter\": {\"type\": \"str\", \"optional\": True},\n",
    "    \"user_metadata\": {\"type\": \"dict[str, any]\", \"optional\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1331929-c6ca-459f-910e-87a28f8923cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DQX_RESULT_KEYWORDS = {\n",
    "    \"criticality\": {\n",
    "        \"values\": [\"error\", \"warn\"],\n",
    "        \"description\": \"Severity level for the rule—shows up in dashboards/results.\"\n",
    "    },\n",
    "    \"_errors\": {\n",
    "        \"description\": \"Column auto-added by DQX to result DF, contains error violations\"\n",
    "    },\n",
    "    \"_warnings\": {\n",
    "        \"description\": \"Column auto-added by DQX to result DF, contains warning violations\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "369bb620-3f62-48e5-a1ca-54c68653cafe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Yaml-defined Rules Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eddb099-4a7f-49c8-8ca9-367477964569",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Template"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Section 1 – Simple row‑level checks\n",
    "#\n",
    "# These rules operate on a single column at a time for each row.  Only the\n",
    "# `column` argument is mandatory.  Additional arguments apply only to certain\n",
    "# functions and are shown commented out with explanations.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error                 # 'error' => quarantine row on failure; 'warn' => flag but keep row\n",
    "  check:\n",
    "    function: is_not_null            # any row-level built-in function\n",
    "    arguments:\n",
    "      column: col1                   # name or expression of a column in the table being checked\n",
    "      # allowed: [1, 2, 3]           # for is_in_list / is_not_null_and_is_in_list: values the column must belong to\n",
    "      # min_limit: 0                 # for is_in_range / is_not_in_range: lower bound (inclusive)\n",
    "      # max_limit: 10                # for is_in_range / is_not_in_range: upper bound (inclusive)\n",
    "      # limit: 5                     # for is_not_less_than / is_not_greater_than: numeric/date/timestamp limit\n",
    "      # date_format: yyyy-MM-dd      # for is_valid_date: expected date pattern\n",
    "      # timestamp_format: yyyy-MM-dd HH:mm:ss   # for is_valid_timestamp: expected timestamp pattern\n",
    "      # offset: 86400                # for is_not_in_future / is_not_in_near_future: offset in seconds\n",
    "      # curr_timestamp: '2025-08-05T00:00:00'   # override current timestamp; string or timestamp literal\n",
    "      # days: 7                      # for is_older_than_n_days / is_older_than_col2_for_n_days: number of days\n",
    "      # regex: '[A-Z]{3}[0-9]{4}'    # for regex_match: regular expression pattern\n",
    "      # negate: false                # boolean: set true to invert the check (fail when regex matches, pass otherwise)\n",
    "\n",
    "################################################################################\n",
    "# Section 2 – Row‑level checks applied to multiple columns individually\n",
    "#\n",
    "# Use `for_each_column` when the same single‑column rule should be executed on\n",
    "# several columns.  Each entry must be a valid column name or expression from\n",
    "# the table being checked.  There is no hard limit on the number of columns.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_not_null\n",
    "    for_each_column:\n",
    "      - col1                         # first column name in the dataset\n",
    "      - col2                         # second column name in the dataset\n",
    "      # - col3                      # add additional column names as needed; each must exist in the dataset\n",
    "\n",
    "################################################################################\n",
    "# Section 3 – Row‑level checks on complex types (struct, map, array)\n",
    "#\n",
    "# These templates target elements within complex columns.  Use dot notation\n",
    "# (`struct_field`) for struct fields, and `try_element_at` for map or array\n",
    "# elements.  For array aggregations (e.g. max/min), include a numeric limit.\n",
    "################################################################################\n",
    "\n",
    "# Single element from a complex type\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_not_null\n",
    "    arguments:\n",
    "      column: col8.field1            # struct field; must refer to an existing field\n",
    "      # column: try_element_at(col7, 'key1')  # map element lookup; key must exist\n",
    "      # column: try_element_at(col4, 0)       # array element lookup by zero-based index\n",
    "      # Any optional parameters from Section 1 can be included here (e.g. regex)\n",
    "\n",
    "# Aggregating an array (e.g. ensure max element ≤ 10)\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_not_greater_than    # or is_not_less_than\n",
    "    arguments:\n",
    "      column: array_max(col4)        # aggregate function applied to an array column\n",
    "      limit: 10                      # required for array aggregation; numeric threshold for comparison\n",
    "\n",
    "################################################################################\n",
    "# Section 4 – Row‑level SQL expression\n",
    "#\n",
    "# For complex row‑level logic, use `sql_expression`.  This rule does not take a\n",
    "# `column` field; instead provide an SQL predicate.  Optional fields allow you to\n",
    "# customise messages, naming and inversion behaviour.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: sql_expression\n",
    "    arguments:\n",
    "      expression: \"col3 >= col2 AND col3 <= 10\"  # SQL predicate; fails when expression is True\n",
    "      # msg: \"col3 out of range\"       # optional message to include in result rows\n",
    "      # name: \"col3_range_check\"       # optional name for the resulting check column (appears in result DataFrame)\n",
    "      # negate: false                  # boolean: set true to invert the logic (fail when expression is False)\n",
    "      # columns: [col2, col3]          # optional list of one or more column names used only for reporting; does not affect logic\n",
    "\n",
    "################################################################################\n",
    "# Section 5 – Dataset‑level uniqueness check\n",
    "#\n",
    "# Ensures that the specified columns are unique across all rows.  A failure is\n",
    "# logged for every duplicate row found.  Use `nulls_distinct` to control how\n",
    "# NULL values are treated.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_unique\n",
    "    arguments:\n",
    "      columns:\n",
    "        - col1                        # key columns (one or more) used to test uniqueness\n",
    "        # - col2                     # add additional columns for composite key\n",
    "      # nulls_distinct: true          # default true: treat NULLs as distinct; set false to consider NULLs equal\n",
    "\n",
    "################################################################################\n",
    "# Section 6 – Dataset‑level aggregation checks\n",
    "#\n",
    "# Compare aggregated values against a threshold.  Specify `aggr_type` (count,\n",
    "# sum, avg, min, max).  For count, omit the column; otherwise provide the\n",
    "# column being aggregated.  `group_by` can list one or more columns to group\n",
    "# rows before aggregation.\n",
    "################################################################################\n",
    "\n",
    "# Count of all rows must not exceed 10\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_aggr_not_greater_than\n",
    "    arguments:\n",
    "      aggr_type: count               # aggregation type (count, sum, avg, min, max)\n",
    "      limit: 10                      # numeric or literal threshold for comparison\n",
    "\n",
    "# Count of non-null values in col2 must not exceed 10\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_aggr_not_greater_than\n",
    "    arguments:\n",
    "      column: col2                   # column to aggregate (omit for count of all rows)\n",
    "      aggr_type: count\n",
    "      limit: 10\n",
    "\n",
    "# Count of col2 grouped by col3 must not exceed 10\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_aggr_not_greater_than\n",
    "    arguments:\n",
    "      column: col2\n",
    "      aggr_type: count\n",
    "      group_by:\n",
    "        - col3                       # one or more grouping columns; must exist in the table\n",
    "      limit: 10\n",
    "\n",
    "################################################################################\n",
    "# Section 7 – Dataset‑level foreign key check\n",
    "#\n",
    "# Validates that values in the source dataset exist in a reference dataset.\n",
    "# Provide either a reference DataFrame name (`ref_df_name`) or a fully qualified\n",
    "# table name (`ref_table`), not both.  `negate` flips the logic to flag rows\n",
    "# that do exist in the reference.\n",
    "################################################################################\n",
    "\n",
    "# Single-column foreign key using a reference DataFrame\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: foreign_key\n",
    "    arguments:\n",
    "      columns:\n",
    "        - col1                       # column(s) in source dataset\n",
    "      ref_columns:\n",
    "        - ref_col1                   # matching column(s) in reference dataset\n",
    "      ref_df_name: ref_df_key        # key to locate the reference DataFrame in ref_dfs\n",
    "      # negate: false                # optional; set true to fail rows that exist in the reference\n",
    "\n",
    "# Composite-key foreign key using a table\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: foreign_key\n",
    "    arguments:\n",
    "      columns:\n",
    "        - col1\n",
    "        - col2\n",
    "      ref_columns:\n",
    "        - ref_col1\n",
    "        - ref_col2\n",
    "      ref_table: catalog.schema.ref_table   # fully qualified table name used as the reference\n",
    "\n",
    "################################################################################\n",
    "# Section 8 – Dataset‑level SQL query\n",
    "#\n",
    "# Executes an arbitrary SQL query across the dataset (and optional reference data).\n",
    "# The query must return all `merge_columns` plus a boolean `condition_column`.\n",
    "# The check fails when the condition column is True (unless `negate` is true).\n",
    "# Use `input_placeholder` to name the input DataFrame within the SQL query.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: sql_query\n",
    "    arguments:\n",
    "      query: |\n",
    "        SELECT col1, col2, SUM(col3) = 0 AS condition\n",
    "        FROM {{ input_view }}                   # placeholder referencing the input dataset\n",
    "        GROUP BY col1, col2\n",
    "      merge_columns:\n",
    "        - col1\n",
    "        - col2\n",
    "      condition_column: condition              # name of the boolean column returned by the query\n",
    "      input_placeholder: input_view            # alias used inside double braces in the SQL\n",
    "      # msg: \"Aggregated col3 is zero\"         # optional message added to result rows\n",
    "      # name: \"check_sum_col3_zero\"            # optional name of the resulting check column\n",
    "      # negate: false                          # optional; set true to invert the meaning (fail when condition is False)\n",
    "\n",
    "################################################################################\n",
    "# Section 9 – Dataset‑level compare datasets\n",
    "#\n",
    "# Compares two datasets at row and column level.  Provide matching key columns\n",
    "# for both source and reference.  You can exclude columns from the comparison\n",
    "# and enable detection of missing records via full outer join.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: compare_datasets\n",
    "    arguments:\n",
    "      columns:\n",
    "        - col1                       # key columns in the source dataset\n",
    "        - col2\n",
    "      ref_columns:\n",
    "        - ref_col1                   # corresponding key columns in the reference dataset\n",
    "        - ref_col2\n",
    "      # ref_df_name: ref_df_key               # OR use ref_table: catalog.schema.ref_table\n",
    "      # exclude_columns:\n",
    "      #   - col7                              # columns to ignore differences for\n",
    "      # check_missing_records: true           # if true, perform FULL OUTER JOIN to detect missing rows; increases result size\n",
    "\n",
    "################################################################################\n",
    "# Section 10 – Dataset‑level multi‑key application (`for_each_column`)\n",
    "#\n",
    "# Use this construct for functions that accept a `columns` argument (e.g.\n",
    "# `is_unique`).  Each inner list defines a distinct key on which the check will\n",
    "# run independently.\n",
    "################################################################################\n",
    "\n",
    "- criticality: error\n",
    "  check:\n",
    "    function: is_unique\n",
    "    for_each_column:\n",
    "      - [col1]                     # first uniqueness key: single column in the dataset\n",
    "      - [col2, col3]               # second key: composite of col2 and col3\n",
    "      # - [col4, col5, col6]       # additional keys; each inner list must contain existing column names\n",
    "\n",
    "################################################################################\n",
    "# End of document\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0226e82f-86f6-4dc1-9996-4a60419c9a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Example Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d40ccf39-4e07-46d5-b7f8-a4e169822c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| animal_id | species | age_years | weight_kg | feeding_schedule | care_info                                      | attributes                          |\n",
    "|-----------|---------|-----------|-----------|------------------|------------------------------------------------|-------------------------------------|\n",
    "| 101       | lion    | 5         | 190.5     | [8, 16]          | {\"keeper\":\"Alice\", \"last_check\":\"2025-07-31\"}  | {\"color\":\"gold\", \"region\":\"Africa\"} |\n",
    "| 102       | tiger   | 3         | 220.0     | [7, 15, 22]      | {\"keeper\":\"Bob\", \"last_check\":\"2025-07-30\"}    | {\"color\":\"orange\", \"pattern\":\"striped\"} |\n",
    "| 103       | giraffe | 8         | 800.0     | [9]              | {\"keeper\":\"Carol\", \"last_check\":\"2025-07-29\"}  | {\"height\":\"tall\"}                   |\n",
    "| 104       | zebra   | 4         | 350.0     | [10, 18]         | {\"keeper\":\"Dave\", \"last_check\":\"2025-07-28\"}   | {\"color\":\"black-white\", \"pattern\":\"striped\"} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90197ebb-73dd-4169-a5ee-d8f48d515d89",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Example"
    }
   },
   "outputs": [],
   "source": [
    "# Section 1 – Simple row-level check\n",
    "# Ensure weight_kg is within a reasonable range [0, 1000].\n",
    "- criticality: error\n",
    "  name: weight_range\n",
    "  check:\n",
    "    function: is_in_range\n",
    "    arguments:\n",
    "      column: weight_kg       # Column from the dataset\n",
    "      min_limit: 0            # Lower bound inclusive\n",
    "      max_limit: 1000         # Upper bound inclusive\n",
    "\n",
    "# Section 2 – Row-level check applied individually\n",
    "# Ensure both age_years and weight_kg are at least 1.\n",
    "- criticality: warn\n",
    "  name: age_weight_min\n",
    "  check:\n",
    "    function: is_not_less_than\n",
    "    for_each_column:\n",
    "      - age_years            # First column to check\n",
    "      - weight_kg            # Second column to check\n",
    "    arguments:\n",
    "      limit: 1               # Minimum allowable value\n",
    "\n",
    "# Section 3 – Complex types\n",
    "# (a) Validate that care_info.last_check is a valid date (format yyyy-MM-dd).\n",
    "- criticality: error\n",
    "  name: valid_last_check\n",
    "  check:\n",
    "    function: is_valid_date\n",
    "    arguments:\n",
    "      column: care_info.last_check\n",
    "      date_format: yyyy-MM-dd\n",
    "\n",
    "# (b) Ensure attributes['pattern'] matches either \"striped\" or \"spotted\".\n",
    "- criticality: warn\n",
    "  name: pattern_regex\n",
    "  check:\n",
    "    function: regex_match\n",
    "    arguments:\n",
    "      column: try_element_at(attributes, 'pattern')\n",
    "      regex: '^(striped|spotted)$'\n",
    "      negate: false          # Fail when the pattern DOESN'T match\n",
    "\n",
    "# (c) Ensure the first element of feeding_schedule is present.\n",
    "- criticality: error\n",
    "  name: first_feed_exists\n",
    "  check:\n",
    "    function: is_not_null\n",
    "    arguments:\n",
    "      column: try_element_at(feeding_schedule, 0)\n",
    "\n",
    "# (d) Ensure no feeding time exceeds 24 hours.\n",
    "- criticality: warn\n",
    "  name: max_feed_le_24\n",
    "  check:\n",
    "    function: is_not_greater_than\n",
    "    arguments:\n",
    "      column: array_max(feeding_schedule)\n",
    "      limit: 24              # Required for array aggregation; must be a number\n",
    "\n",
    "# Section 4 – Row-level SQL expression\n",
    "# Ensure weight_kg is at least 20 times age_years.\n",
    "- criticality: error\n",
    "  name: weight_vs_age_rule\n",
    "  check:\n",
    "    function: sql_expression\n",
    "    arguments:\n",
    "      expression: \"weight_kg >= age_years * 20\"\n",
    "      msg: \"Animal weight is unexpectedly low\"\n",
    "      name: \"weight_vs_age\"\n",
    "      columns: [weight_kg, age_years]  # Columns used for reporting; must exist in table\n",
    "\n",
    "# Section 5 – Dataset-level uniqueness [oai_citation:0‡databrickslabs.github.io](https://databrickslabs.github.io/dqx/docs/reference/quality_rules/#:~:text=Available%20dataset)\n",
    "# Ensure (animal_id, species) combinations are unique; treat NULLs as equal.\n",
    "- criticality: error\n",
    "  name: unique_animal_species\n",
    "  check:\n",
    "    function: is_unique\n",
    "    arguments:\n",
    "      columns: [animal_id, species]\n",
    "      nulls_distinct: false  # NULLs are treated as duplicate values\n",
    "\n",
    "# Section 6 – Dataset-level aggregation [oai_citation:1‡databrickslabs.github.io](https://databrickslabs.github.io/dqx/docs/reference/quality_rules/)\n",
    "# Ensure the average age per species is at least 2 years.\n",
    "- criticality: warn\n",
    "  name: avg_age_per_species\n",
    "  check:\n",
    "    function: is_aggr_not_less_than\n",
    "    arguments:\n",
    "      column: age_years\n",
    "      aggr_type: avg         # Average aggregation\n",
    "      group_by: [species]    # Group by species\n",
    "      limit: 2               # Minimum allowable average\n",
    "\n",
    "# Section 7 – Foreign key\n",
    "# Ensure the keeper exists in an external staff table.\n",
    "- criticality: error\n",
    "  name: keeper_fk_check\n",
    "  check:\n",
    "    function: foreign_key\n",
    "    arguments:\n",
    "      columns: [care_info.keeper]\n",
    "      ref_columns: [keeper_name]\n",
    "      ref_table: catalog.hr.allowed_keepers\n",
    "      negate: false          # Fail when keeper is NOT found in the reference table\n",
    "\n",
    "# Section 8 – Dataset-level SQL query [oai_citation:2‡databrickslabs.github.io](https://databrickslabs.github.io/dqx/docs/reference/quality_rules/#:~:text=,%28optional%29%20name%20of)\n",
    "# Ensure there are at least two animals of each species.\n",
    "- criticality: error\n",
    "  name: species_count_check\n",
    "  check:\n",
    "    function: sql_query\n",
    "    arguments:\n",
    "      query: |\n",
    "        SELECT species,\n",
    "               COUNT(*) < 2 AS condition      -- condition = True when there are < 2 animals\n",
    "        FROM {{ input_view }}\n",
    "        GROUP BY species\n",
    "      merge_columns: [species]                # Join key back to input dataset\n",
    "      condition_column: condition             # Boolean column; True means failure\n",
    "      input_placeholder: input_view           # Placeholder name used in query\n",
    "      msg: \"Species has fewer than two animals\"\n",
    "      name: \"min_two_animals_per_species\"\n",
    "\n",
    "# Section 9 – Compare datasets [oai_citation:3‡databrickslabs.github.io](https://databrickslabs.github.io/dqx/docs/reference/quality_rules/#:~:text=systems.,missing%20from%20source%20or%20reference)\n",
    "# Compare current animals against last week's snapshot by animal_id, ignoring weight.\n",
    "- criticality: warn\n",
    "  name: compare_animals\n",
    "  check:\n",
    "    function: compare_datasets\n",
    "    arguments:\n",
    "      columns: [animal_id]\n",
    "      ref_columns: [animal_id]\n",
    "      ref_df_name: last_week                 # Reference DataFrame name\n",
    "      exclude_columns: [weight_kg]           # Ignore weight differences\n",
    "      check_missing_records: true            # Identify missing or new animal_ids\n",
    "\n",
    "# Section 10 – Multi-key uniqueness\n",
    "# Ensure both animal_id and (species, care_info.keeper) keys are unique.\n",
    "- criticality: error\n",
    "  name: multi_key_uniqueness\n",
    "  check:\n",
    "    function: is_unique\n",
    "    for_each_column:\n",
    "      - [animal_id]                          # First key\n",
    "      - [species, care_info.keeper]          # Second key (composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92e9b611-d414-4d52-90f6-c85e81d3439c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Custom Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b6febd0-82cf-4a4f-83fa-7ba438b96732",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "wkdy_dim_project.yaml"
    }
   },
   "outputs": [],
   "source": [
    "#Dataset level\n",
    "- check:\n",
    "  arguments:\n",
    "    columns: project_key\n",
    "  function: is_unique\n",
    "  criticality: error\n",
    "name: project_key_is_not_unique\n",
    "#row level\n",
    "- check:\n",
    "    arguments:\n",
    "      column: project_key\n",
    "    function: is_not_null\n",
    "  criticality: error\n",
    "  name: project_key_is_null\n",
    "  \n",
    "- check:\n",
    "    arguments:\n",
    "      column: project_status\n",
    "    function: is_not_null\n",
    "  criticality: error\n",
    "  name: project_status_is_null\n",
    "  \n",
    "  - check:\n",
    "    arguments:\n",
    "      allowed:\n",
    "        - Active\n",
    "        - Closed\n",
    "        - Pending Close\n",
    "        - Schedule Pending\n",
    "        - Suspended\n",
    "      column: project_status\n",
    "    function: is_in_list\n",
    "  criticality: warning\n",
    "  name: project_status_is_new_value\n",
    "  \n",
    " # project type is not null or Unknown\n",
    " - check:\n",
    "    arguments:\n",
    "      expression: project_type_name is not null AND project_type_name != 'Unknown'\n",
    "    function: sql_expression\n",
    "  criticality: warning\n",
    "  name: project_type_is_not_null_or_unknown\n",
    "\n",
    " #check if email matches\n",
    "- check:\n",
    "    function: regex_match\n",
    "    arguments:\n",
    "      column: email\n",
    "      regex: '^(.+)@(.+)$'\n",
    "  criticality: warning\n",
    "  name: email_is_not_valid\n",
    " \n",
    "- check:  \n",
    "    arguments:\n",
    "        expression: coalesce(project_start_date, '1900-01-01') <= (coalesce(project_end_date, '9999-12-31'))\n",
    "    criticality: warning\n",
    "    function: sql_expression\n",
    "    name: project_start_after_end_date\n",
    "   \n",
    "- check:\n",
    "    criticality: warning\n",
    "    function: sql_expression\n",
    "    arguments:\n",
    "        expression: coalesce(first_activity_date, '1900-01-01') <= (coalesce(last_activity_date, '9999-12-31'))\n",
    "    name: first_activity_date_after_last_activity_date\n",
    " \n",
    "- check:\n",
    "    criticality: warning\n",
    "    function: sql_expression\n",
    "    arguments:\n",
    "        expression: coalesce(_created_date, '1900-01-01') <= (coalesce(_last_updated_date, '9999-12-31'))\n",
    "    name: created_date_after_last_updated_date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9d8644b-759a-42d7-99a4-905aa5a39f93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07b2ed7f-b5ce-4d87-89eb-7c717e40e594",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install and Restart DQX"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "257cf264-be1e-48cd-90f7-42bc3cec1476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DQX_POC",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
