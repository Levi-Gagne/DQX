{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e98fb36c-b673-4140-bf7f-8a226593588e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DQX Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "741d1b4d-9dab-4424-af24-2b4f7595d366",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aaed083-9fc6-4749-b522-9e2b87b3f0d3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DQX_Overview_.lvdash.json"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"version\": \"1\",\n",
    "  \"displayName\": \"DQX â€“ Quality Overview\",\n",
    "  \"pages\": [\n",
    "    {\n",
    "      \"name\": \"overview\",\n",
    "      \"displayName\": \"Overview\",\n",
    "      \"widgets\": [\n",
    "        { \"name\": \"w_kpi\", \"displayName\": \"KPI (rows vs events)\", \"dataset\": \"ds_kpi\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 0, \"y\": 0, \"w\": 8, \"h\": 6 } },\n",
    "        { \"name\": \"w_by_day\", \"displayName\": \"Events by day\", \"dataset\": \"ds_by_day\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 8, \"y\": 0, \"w\": 8, \"h\": 6 } },\n",
    "        { \"name\": \"w_by_check\", \"displayName\": \"Events by check\", \"dataset\": \"ds_by_check\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 0, \"y\": 6, \"w\": 8, \"h\": 8 } },\n",
    "        { \"name\": \"w_by_table\", \"displayName\": \"Events by table\", \"dataset\": \"ds_by_table\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 8, \"y\": 6, \"w\": 8, \"h\": 8 } },\n",
    "        { \"name\": \"w_by_column\", \"displayName\": \"Events by column\", \"dataset\": \"ds_by_column\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 0, \"y\": 14, \"w\": 8, \"h\": 8 } },\n",
    "        { \"name\": \"w_by_run_cfg\", \"displayName\": \"Events by run_config\", \"dataset\": \"ds_by_run_config\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 8, \"y\": 14, \"w\": 8, \"h\": 8 } },\n",
    "        { \"name\": \"w_patterns\", \"displayName\": \"Top error patterns\", \"dataset\": \"ds_error_patterns\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 0, \"y\": 22, \"w\": 8, \"h\": 8 } },\n",
    "        { \"name\": \"w_top_msgs\", \"displayName\": \"Top error messages\", \"dataset\": \"ds_top_error_messages\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 8, \"y\": 22, \"w\": 8, \"h\": 8 } },\n",
    "        { \"name\": \"w_detail\", \"displayName\": \"Recent events (detail)\", \"dataset\": \"ds_detail\", \"visualization\": { \"type\": \"table\" }, \"position\": { \"x\": 0, \"y\": 30, \"w\": 16, \"h\": 10 } }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"datasets\": [\n",
    "    {\n",
    "      \"name\": \"ds_kpi\",\n",
    "      \"displayName\": \"KPI\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT rows_with_any_issue, rows_with_errors, rows_with_warnings, error_events, warning_events, avg_errors_per_row, avg_warnings_per_row, first_ingest_at, last_ingest_at FROM dq_dev.dqx.dashboard_kpi\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_by_day\",\n",
    "      \"displayName\": \"Events by day\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT day, error_events, warning_events FROM dq_dev.dqx.dashboard_events_by_day ORDER BY day\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_by_check\",\n",
    "      \"displayName\": \"Events by check\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT check_name, error_events, warning_events FROM dq_dev.dqx.dashboard_events_by_check ORDER BY error_events DESC, warning_events DESC\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_by_table\",\n",
    "      \"displayName\": \"Events by table\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT table_name, error_events, warning_events FROM dq_dev.dqx.dashboard_events_by_table ORDER BY error_events DESC, warning_events DESC\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_by_column\",\n",
    "      \"displayName\": \"Events by column\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT column, error_events, warning_events FROM dq_dev.dqx.dashboard_events_by_column ORDER BY error_events DESC, warning_events DESC\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_by_run_config\",\n",
    "      \"displayName\": \"Events by run_config\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT run_config_name, error_events, warning_events FROM dq_dev.dqx.dashboard_events_by_run_config ORDER BY error_events DESC, warning_events DESC\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_error_patterns\",\n",
    "      \"displayName\": \"Error patterns\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT error_pattern, rows_hit, sample_table, sample_run_config, sample_check_name, sample_message FROM dq_dev.dqx.dashboard_error_patterns ORDER BY rows_hit DESC LIMIT 200\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_top_error_messages\",\n",
    "      \"displayName\": \"Top error messages\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT message, error_events FROM dq_dev.dqx.dashboard_top_error_messages ORDER BY error_events DESC LIMIT 100\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ds_detail\",\n",
    "      \"displayName\": \"Events detail\",\n",
    "      \"dataSource\": { \"type\": \"WAREHOUSE\", \"warehouseId\": \"ca5a45e27debab49\" },\n",
    "      \"query\": \"SELECT e.table_name, e.check_name, e.message, e.function, e.filter, e.severity, e.run_time, kv.null_count, kv.empty_count, kv.zero_count FROM dq_dev.dqx.dashboard_events e LEFT JOIN dq_dev.dqx.dashboard_row_value_stats kv USING (log_id) ORDER BY e.run_time DESC LIMIT 1000\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50fc6614-ac81-4e6d-a3df-b1bc9dbb7da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82090f6b-1313-4a32-a4bf-960bf386cb6c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install and Launch Databricks DQX Dashboards"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk\n",
    "%pip install databricks-labs-dqx==0.8.0\n",
    "%databricks labs dqx open-dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61565af4-13a0-434a-a22e-b32284f2b644",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python Environment"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a9ff683-d53e-4d33-8103-a022602ee2f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.labs.dqx.contexts.workspace import WorkspaceContext\n",
    "\n",
    "# Optional: make the link clickable in the notebook\n",
    "def _display_html_link(url: str, label: str = None):\n",
    "    try:\n",
    "        displayHTML(f'<a href=\"{url}\" target=\"_blank\">{label or url}</a>')\n",
    "    except Exception:\n",
    "        print(url)\n",
    "\n",
    "# Build the base link to the dashboards \"folder\" in your workspace\n",
    "ctx = WorkspaceContext(WorkspaceClient())\n",
    "dashboards_folder_link = f\"{ctx.installation.workspace_link('')}dashboards/\"\n",
    "\n",
    "print(\"Open a dashboard from this folder, then hit Refresh inside the dashboard:\")\n",
    "print(dashboards_folder_link)\n",
    "_display_html_link(dashboards_folder_link, \"Open DQX dashboards folder\")\n",
    "\n",
    "# (Optional) If you know a specific dashboard path (from the UI),\n",
    "# you can deep-link to it like this:\n",
    "# my_dash_relpath = \"dashboards/Shared/DQX/Quality Overview\"  # example path after you open the folder and copy link\n",
    "# my_dash_link = f\"{ctx.installation.workspace_link('')}{my_dash_relpath}\"\n",
    "# print(\"Direct dashboard link:\")\n",
    "# _display_html_link(my_dash_link, \"Open: DQX â€“ Quality Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4440c58-8fd7-4252-a090-2cafca1d8c1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.labs.dqx.contexts.workspace import WorkspaceContext\n",
    "\n",
    "ctx = WorkspaceContext(WorkspaceClient())\n",
    "dashboards_folder_link = f\"{ctx.installation.workspace_link('')}dashboards/\"\n",
    "print(f\"Open a dashboard from the following folder and refresh it:\")\n",
    "print(dashboards_folder_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03ec41fd-686f-4025-9a28-20127a8c7992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Custom DQX Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f84301a-2d87-41eb-bc49-3d3d6a3e4056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Authoritative `dashboard_*` Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc783c37-55d8-41d8-b0d1-a4c2c3fa550e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DQX dashboard base & tiles (idempotent)\n",
    "USE CATALOG dq_dev;\n",
    "USE SCHEMA dqx;\n",
    "\n",
    "-- Clean\n",
    "DROP VIEW IF EXISTS dashboard_errors;\n",
    "DROP VIEW IF EXISTS dashboard_warnings;\n",
    "DROP VIEW IF EXISTS dashboard_events;\n",
    "DROP VIEW IF EXISTS dashboard_row_kv;\n",
    "DROP VIEW IF EXISTS dashboard_row_value_stats;\n",
    "DROP VIEW IF EXISTS dashboard_kpi;\n",
    "DROP VIEW IF EXISTS dashboard_error_patterns;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_day;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_check;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_table;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_column;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_run_config;\n",
    "DROP VIEW IF EXISTS dashboard_top_error_messages;\n",
    "DROP VIEW IF EXISTS dashboard_rules_catalog;\n",
    "DROP VIEW IF EXISTS dashboard_rules_affected;\n",
    "DROP VIEW IF EXISTS dashboard_rules_coverage;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1efd40-4475-4982-b1fb-0ea12893f4ca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Clean and Create Views for Dashboard Events"
    }
   },
   "outputs": [],
   "source": [
    "-- ======================================================================\n",
    "-- DQX Dashboard Layer (Materialized Views)\n",
    "-- Source of truth: dq_dev.dqx.checks_log  (arrays with per-issue check_id[])\n",
    "-- Rules table:      dq_dev.dqx.checks\n",
    "-- ======================================================================\n",
    "\n",
    "USE CATALOG dq_dev;\n",
    "USE SCHEMA dqx;\n",
    "\n",
    "-- ----------------------------------------------------------------------\n",
    "-- Clean old objects (idempotent)\n",
    "-- ----------------------------------------------------------------------\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_row_kv_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_event_kv_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_day_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_table_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_check_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_run_config_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_column_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_top_error_messages_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_event_check_ids_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_enriched_mv;\n",
    "\n",
    "-- ======================================================================\n",
    "-- 1) Flatten issues (one row per issue element), both ERROR and WARN\n",
    "--    - Keeps the issue-level check_id ARRAY (no extra fan-out here)\n",
    "--    - Adds a stable event_id (log_id + side + position)\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_events_mv AS\n",
    "WITH errs AS (\n",
    "  SELECT\n",
    "    'ERROR'                       AS severity,\n",
    "    l.log_id,\n",
    "    l.table_name,\n",
    "    l.run_config_name,\n",
    "    e.name                        AS check_name,\n",
    "    e.message,\n",
    "    e.function,\n",
    "    e.filter,\n",
    "    e.columns                     AS rule_columns,          -- ARRAY<STRING>\n",
    "    e.user_metadata,\n",
    "    e.check_id                    AS check_id,              -- ARRAY<STRING> (from writer)\n",
    "    e.run_time,\n",
    "    l.created_at,\n",
    "    l._errors_fingerprint         AS pattern_fingerprint,\n",
    "    l.row_snapshot_fingerprint    AS row_fp,\n",
    "    p.pos                         AS pos\n",
    "  FROM dq_dev.dqx.checks_log l\n",
    "  LATERAL VIEW OUTER posexplode(_errors) p AS pos, e\n",
    "),\n",
    "warns AS (\n",
    "  SELECT\n",
    "    'WARN'                        AS severity,\n",
    "    l.log_id,\n",
    "    l.table_name,\n",
    "    l.run_config_name,\n",
    "    w.name                        AS check_name,\n",
    "    w.message,\n",
    "    w.function,\n",
    "    w.filter,\n",
    "    w.columns                     AS rule_columns,          -- ARRAY<STRING>\n",
    "    w.user_metadata,\n",
    "    w.check_id                    AS check_id,              -- ARRAY<STRING> (from writer)\n",
    "    w.run_time,\n",
    "    l.created_at,\n",
    "    l._warnings_fingerprint       AS pattern_fingerprint,\n",
    "    l.row_snapshot_fingerprint    AS row_fp,\n",
    "    p.pos                         AS pos\n",
    "  FROM dq_dev.dqx.checks_log l\n",
    "  LATERAL VIEW OUTER posexplode(_warnings) p AS pos, w\n",
    ")\n",
    "SELECT\n",
    "  sha2(concat(log_id, CASE WHEN severity='ERROR' THEN ':E:' ELSE ':W:' END, cast(pos AS STRING)), 256) AS event_id,\n",
    "  *\n",
    "EXCEPT(pos)\n",
    "FROM (SELECT * FROM errs UNION ALL SELECT * FROM warns);\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_mv IS\n",
    "'Issue-level events (1 row per error/warn element). Includes check_id ARRAY inside each issue.';\n",
    "\n",
    "\n",
    "-- ======================================================================\n",
    "-- 2) Row KV: explode row_snapshot into (column, value) pairs\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_row_kv_mv AS\n",
    "SELECT\n",
    "  l.log_id,\n",
    "  l.table_name,\n",
    "  l.run_config_name,\n",
    "  l.created_at,\n",
    "  kv.column AS column,\n",
    "  kv.value  AS value,\n",
    "  CASE WHEN kv.value IS NULL THEN TRUE ELSE FALSE END                                    AS is_null,\n",
    "  CASE WHEN kv.value IS NOT NULL AND length(trim(kv.value)) = 0 THEN TRUE ELSE FALSE END AS is_empty,\n",
    "  CASE WHEN TRY_CAST(kv.value AS DOUBLE) = 0 THEN TRUE ELSE FALSE END                    AS is_zero\n",
    "FROM dq_dev.dqx.checks_log l\n",
    "LATERAL VIEW OUTER explode(row_snapshot) s AS kv;\n",
    "\n",
    "COMMENT ON TABLE dashboard_row_kv_mv IS\n",
    "'Row snapshot exploded into key/value pairs with simple null/empty/zero flags.';\n",
    "\n",
    "\n",
    "-- ======================================================================\n",
    "-- 3) Event Ã— KV (scoped): only KV columns relevant to the rule\n",
    "--    If rule_columns is NULL, include all columns for that row.\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_event_kv_mv AS\n",
    "SELECT\n",
    "  e.event_id,\n",
    "  e.severity,\n",
    "  e.log_id,\n",
    "  e.table_name,\n",
    "  e.run_config_name,\n",
    "  e.check_name,\n",
    "  e.function,\n",
    "  e.filter,\n",
    "  e.rule_columns,     -- ARRAY<STRING>\n",
    "  e.check_id,         -- ARRAY<STRING>\n",
    "  e.run_time,\n",
    "  e.created_at,\n",
    "  e.pattern_fingerprint,\n",
    "  e.row_fp,\n",
    "  kv.column,\n",
    "  kv.value,\n",
    "  kv.is_null,\n",
    "  kv.is_empty,\n",
    "  kv.is_zero\n",
    "FROM dashboard_events_mv e\n",
    "JOIN dashboard_row_kv_mv kv\n",
    "  ON kv.log_id = e.log_id\n",
    "WHERE e.rule_columns IS NULL OR array_contains(e.rule_columns, kv.column);\n",
    "\n",
    "COMMENT ON TABLE dashboard_event_kv_mv IS\n",
    "'Event rows joined to the relevant per-row KV pairs (restricted to columns referenced by the rule when provided).';\n",
    "\n",
    "\n",
    "-- ======================================================================\n",
    "-- 4) Helper MV: fan out event_id â†’ individual check_id (many-to-many)\n",
    "--    Makes joins to dq_dev.dqx.checks trivial and avoids duplicating\n",
    "--    rows in dashboard_events_mv.\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_event_check_ids_mv AS\n",
    "SELECT\n",
    "  e.event_id,\n",
    "  cid AS check_id\n",
    "FROM dashboard_events_mv e\n",
    "LATERAL VIEW OUTER explode(e.check_id) c AS cid;\n",
    "\n",
    "COMMENT ON TABLE dashboard_event_check_ids_mv IS\n",
    "'Mapping of event_id to each check_id (1 row per check_id per event).';\n",
    "\n",
    "\n",
    "-- ======================================================================\n",
    "-- 5) Enriched events: join rule metadata/arguments via check_id\n",
    "--    - Produces 0..N rows per event depending on how many check_id matches\n",
    "--    - Exposes arguments JSON for parameterized post-analytics\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_events_enriched_mv AS\n",
    "SELECT\n",
    "  e.event_id,\n",
    "  e.severity,\n",
    "  e.log_id,\n",
    "  e.table_name,\n",
    "  e.run_config_name,\n",
    "  e.check_name,\n",
    "  ec.check_id                            AS check_id,\n",
    "  r.name                                 AS config_rule_name,\n",
    "  r.criticality                          AS config_criticality,\n",
    "  r.filter                               AS config_filter,\n",
    "  r.run_config_name                      AS config_run_config_name,\n",
    "  to_json(r.check)                       AS config_check_json,\n",
    "  to_json(r.check.arguments)             AS config_arguments_json,\n",
    "  e.function,\n",
    "  e.filter,\n",
    "  e.rule_columns,\n",
    "  e.message,\n",
    "  e.user_metadata,\n",
    "  e.run_time,\n",
    "  e.created_at,\n",
    "  e.pattern_fingerprint,\n",
    "  e.row_fp\n",
    "FROM dashboard_events_mv e\n",
    "LEFT JOIN dashboard_event_check_ids_mv ec\n",
    "  ON ec.event_id = e.event_id\n",
    "LEFT JOIN dq_dev.dqx.checks r\n",
    "  ON r.check_id = ec.check_id;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_enriched_mv IS\n",
    "'Events with per-check enrichment (joins dq_dev.dqx.checks via check_id). Includes arguments JSON for parameterized analysis.';\n",
    "\n",
    "\n",
    "-- ======================================================================\n",
    "-- 6) Common aggregations (materialized for speed)\n",
    "-- ======================================================================\n",
    "\n",
    "-- By day (run_time)\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_day_mv AS\n",
    "SELECT\n",
    "  date_trunc('day', run_time) AS day,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY date_trunc('day', run_time);\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_day_mv IS\n",
    "'Daily counts of error/warn events based on event run_time.';\n",
    "\n",
    "\n",
    "-- By table\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_table_mv AS\n",
    "SELECT\n",
    "  table_name,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY table_name;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_table_mv IS\n",
    "'Counts of error/warn events per table.';\n",
    "\n",
    "\n",
    "-- By check (issue name in the log; use *_enriched_mv for config.name)\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_check_mv AS\n",
    "SELECT\n",
    "  COALESCE(check_name, 'unknown')        AS check_name,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY COALESCE(check_name, 'unknown');\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_check_mv IS\n",
    "'Counts of error/warn events per check_name (from the log).';\n",
    "\n",
    "\n",
    "-- By run_config\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_run_config_mv AS\n",
    "SELECT\n",
    "  run_config_name,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY run_config_name;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_run_config_mv IS\n",
    "'Counts of error/warn events per run_config_name.';\n",
    "\n",
    "\n",
    "-- By column (scoped event Ã— KV)\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_column_mv AS\n",
    "SELECT\n",
    "  column,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_event_kv_mv\n",
    "GROUP BY column;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_column_mv IS\n",
    "'Counts of error/warn events per column, considering only columns referenced by the rule when available.';\n",
    "\n",
    "\n",
    "-- Top error messages (dedup by message text)\n",
    "CREATE MATERIALIZED VIEW dashboard_top_error_messages_mv AS\n",
    "SELECT\n",
    "  message,\n",
    "  COUNT(*) AS error_events\n",
    "FROM dashboard_events_mv\n",
    "WHERE severity = 'ERROR'\n",
    "GROUP BY message\n",
    "ORDER BY error_events DESC;\n",
    "\n",
    "COMMENT ON TABLE dashboard_top_error_messages_mv IS\n",
    "'Most frequent error messages across all events.';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee753c3-ea94-469e-bcf8-7b6f506d2497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lakeview DQX Dashboard via SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcc5787b-9220-4bb8-9610-56d9bccdda14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q databricks-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d124d6-3e48-4046-a8bd-2fe236f57b26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f82deb-142d-4949-9694-a4f1852fa28d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.dashboards import (\n",
    "    Dashboard as LvDashboard,\n",
    "    Schedule, CronSchedule, SchedulePauseStatus\n",
    ")\n",
    "\n",
    "# --- config ---\n",
    "WAREHOUSE_ID   = \"ca5a45e27debab49\"\n",
    "SCHEDULE_EVERY_MIN = 30\n",
    "SCHEDULE_TZ    = \"America/Chicago\"     # pick your workspace/viewer TZ\n",
    "DISPLAY_NAME   = \"DQX â€“ Quality Overview\"\n",
    "PARENT_PATH    = \"/Users/levi.gagne@claconnect.com/DQX\"\n",
    "JSON_REL_PATH  = \"dashboards/DQX_Overview.lvdash.json\"\n",
    "\n",
    "# --- resolve repo file to /Workspace path ---\n",
    "nb_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "repo_dir = os.path.dirname(nb_path)\n",
    "json_ws_path = f\"{repo_dir}/{JSON_REL_PATH}\".replace(\"//\", \"/\")\n",
    "json_local = \"/Workspace\" + json_ws_path\n",
    "\n",
    "print(f\"Reading dashboard JSON: {json_local}\")\n",
    "with open(json_local, \"r\", encoding=\"utf-8\") as f:\n",
    "    serialized = f.read()\n",
    "\n",
    "# optional templating\n",
    "serialized = serialized.replace(\"{{WAREHOUSE_ID}}\", WAREHOUSE_ID)\n",
    "_ = json.loads(serialized)  # validate JSON\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# ensure parent folder\n",
    "try:\n",
    "    w.workspace.get_status(PARENT_PATH)\n",
    "except Exception:\n",
    "    w.workspace.mkdirs(PARENT_PATH)\n",
    "\n",
    "# create draft dashboard from serialized JSON\n",
    "dash = w.lakeview.create(LvDashboard(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    warehouse_id=WAREHOUSE_ID,\n",
    "    parent_path=PARENT_PATH,\n",
    "    serialized_dashboard=serialized\n",
    "))\n",
    "DASHBOARD_ID = dash.dashboard_id\n",
    "print(\"dashboard_id:\", DASHBOARD_ID)\n",
    "\n",
    "# publish so we can attach schedules/subscriptions\n",
    "w.lakeview.publish(DASHBOARD_ID)\n",
    "\n",
    "# --- upsert schedule (avoid duplicates by display_name) ---\n",
    "cron = f\"0 0/{SCHEDULE_EVERY_MIN} * ? * *\"   # every N minutes\n",
    "sched_payload = Schedule(\n",
    "    display_name=f\"Every {SCHEDULE_EVERY_MIN} minutes\",\n",
    "    cron_schedule=CronSchedule(quartz_cron_expression=cron, timezone_id=SCHEDULE_TZ),\n",
    "    pause_status=SchedulePauseStatus.UNPAUSED,\n",
    "    warehouse_id=WAREHOUSE_ID\n",
    ")\n",
    "\n",
    "existing = next((s for s in w.lakeview.list_schedules(DASHBOARD_ID)\n",
    "                 if getattr(s, \"display_name\", None) == sched_payload.display_name), None)\n",
    "\n",
    "if existing:\n",
    "    upd = w.lakeview.update_schedule(DASHBOARD_ID, existing.schedule_id, sched_payload)\n",
    "    schedule_id = upd.schedule_id\n",
    "    print(\"schedule_id (updated):\", schedule_id)\n",
    "else:\n",
    "    created = w.lakeview.create_schedule(DASHBOARD_ID, sched_payload)\n",
    "    schedule_id = created.schedule_id\n",
    "    print(\"schedule_id (created):\", schedule_id)\n",
    "\n",
    "# URL to open\n",
    "base = w.config.host.rstrip(\"/\")\n",
    "print(\"dashboard url:\", f\"{base}/dashboardsv3/{DASHBOARD_ID}\")\n",
    "\n",
    "# export the server-enriched snapshot for Git\n",
    "server_def = w.lakeview.get(DASHBOARD_ID)\n",
    "snapshot = server_def.serialized_dashboard or \"\"\n",
    "snap_path = \"/Workspace\" + f\"{repo_dir}/dashboards/DQX_Overview.snapshot.lvdash.json\"\n",
    "with open(snap_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(snapshot)\n",
    "print(\"snapshot written:\", snap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "179c1675-a23b-4090-84d3-09d96cc2fdad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "NOTES: Not sure if this is repeated, but found in another file . . . consolidating info for archive - 2025-08-24"
    }
   },
   "outputs": [],
   "source": [
    "#    DASHBOARD QUIRIES TO timestamp\n",
    "\n",
    "\n",
    "-- ======================================================================\n",
    "-- DQX Dashboard Layer (Materialized Views)\n",
    "-- Source of truth: dq_dev.dqx.checks_log  (arrays with per-issue check_id[])\n",
    "-- Rules table:      dq_dev.dqx.checks\n",
    "-- ======================================================================\n",
    "\n",
    "USE CATALOG dq_dev;\n",
    "USE SCHEMA dqx;\n",
    "\n",
    "-- ----------------------------------------------------------------------\n",
    "-- Clean old objects (idempotent)\n",
    "-- ----------------------------------------------------------------------\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_row_kv_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_event_kv_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_day_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_table_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_check_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_run_config_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_by_column_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_top_error_messages_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_event_check_ids_mv;\n",
    "DROP MATERIALIZED VIEW IF EXISTS dashboard_events_enriched_mv;\n",
    "\n",
    "-- ======================================================================\n",
    "-- 1) Flatten issues (1 row per issue element), both ERROR and WARN\n",
    "--    - Preserves issue-level check_id ARRAY\n",
    "--    - Adds stable event_id (log_id + side + position)\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_events_mv AS\n",
    "WITH errs AS (\n",
    "  SELECT\n",
    "    'ERROR'                       AS severity,\n",
    "    l.log_id,\n",
    "    l.table_name,\n",
    "    l.run_config_name,\n",
    "    e.name                        AS check_name,\n",
    "    e.message,\n",
    "    e.function,\n",
    "    e.filter,\n",
    "    e.columns                     AS rule_columns,          -- ARRAY<STRING>\n",
    "    e.user_metadata,\n",
    "    e.check_id                    AS check_id,              -- ARRAY<STRING>\n",
    "    e.run_time,\n",
    "    l.created_at,\n",
    "    l._errors_fingerprint         AS pattern_fingerprint,\n",
    "    l.row_snapshot_fingerprint    AS row_fp,\n",
    "    p.pos                         AS pos\n",
    "  FROM dq_dev.dqx.checks_log l\n",
    "  LATERAL VIEW OUTER posexplode(_errors) p AS pos, e\n",
    "),\n",
    "warns AS (\n",
    "  SELECT\n",
    "    'WARN'                        AS severity,\n",
    "    l.log_id,\n",
    "    l.table_name,\n",
    "    l.run_config_name,\n",
    "    w.name                        AS check_name,\n",
    "    w.message,\n",
    "    w.function,\n",
    "    w.filter,\n",
    "    w.columns                     AS rule_columns,          -- ARRAY<STRING>\n",
    "    w.user_metadata,\n",
    "    w.check_id                    AS check_id,              -- ARRAY<STRING>\n",
    "    w.run_time,\n",
    "    l.created_at,\n",
    "    l._warnings_fingerprint       AS pattern_fingerprint,\n",
    "    l.row_snapshot_fingerprint    AS row_fp,\n",
    "    p.pos                         AS pos\n",
    "  FROM dq_dev.dqx.checks_log l\n",
    "  LATERAL VIEW OUTER posexplode(_warnings) p AS pos, w\n",
    ")\n",
    "SELECT\n",
    "  sha2(concat(log_id, CASE WHEN severity='ERROR' THEN ':E:' ELSE ':W:' END, cast(pos AS STRING)), 256) AS event_id,\n",
    "  *\n",
    "EXCEPT(pos)\n",
    "FROM (SELECT * FROM errs UNION ALL SELECT * FROM warns);\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_mv IS\n",
    "'Issue-level events (1 row per error/warn element). Includes check_id ARRAY inside each issue.';\n",
    "\n",
    "-- ======================================================================\n",
    "-- 2) Row KV: explode row_snapshot into (column, value) pairs\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_row_kv_mv AS\n",
    "SELECT\n",
    "  l.log_id,\n",
    "  l.table_name,\n",
    "  l.run_config_name,\n",
    "  l.created_at,\n",
    "  kv.column AS column,\n",
    "  kv.value  AS value,\n",
    "  CASE WHEN kv.value IS NULL THEN TRUE ELSE FALSE END                                    AS is_null,\n",
    "  CASE WHEN kv.value IS NOT NULL AND length(trim(kv.value)) = 0 THEN TRUE ELSE FALSE END AS is_empty,\n",
    "  CASE WHEN TRY_CAST(kv.value AS DOUBLE) = 0 THEN TRUE ELSE FALSE END                    AS is_zero\n",
    "FROM dq_dev.dqx.checks_log l\n",
    "LATERAL VIEW OUTER explode(row_snapshot) s AS kv;\n",
    "\n",
    "COMMENT ON TABLE dashboard_row_kv_mv IS\n",
    "'Row snapshot exploded into key/value pairs with simple null/empty/zero flags.';\n",
    "\n",
    "-- ======================================================================\n",
    "-- 3) Event Ã— KV (scoped to rule columns)\n",
    "--    If rule_columns is NULL, include all columns for that row.\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_event_kv_mv AS\n",
    "SELECT\n",
    "  e.event_id,\n",
    "  e.severity,\n",
    "  e.log_id,\n",
    "  e.table_name,\n",
    "  e.run_config_name,\n",
    "  e.check_name,\n",
    "  e.function,\n",
    "  e.filter,\n",
    "  e.rule_columns,     -- ARRAY<STRING>\n",
    "  e.check_id,         -- ARRAY<STRING>\n",
    "  e.run_time,\n",
    "  e.created_at,\n",
    "  e.pattern_fingerprint,\n",
    "  e.row_fp,\n",
    "  kv.column,\n",
    "  kv.value,\n",
    "  kv.is_null,\n",
    "  kv.is_empty,\n",
    "  kv.is_zero\n",
    "FROM dashboard_events_mv e\n",
    "JOIN dashboard_row_kv_mv kv\n",
    "  ON kv.log_id = e.log_id\n",
    "WHERE e.rule_columns IS NULL OR array_contains(e.rule_columns, kv.column);\n",
    "\n",
    "COMMENT ON TABLE dashboard_event_kv_mv IS\n",
    "'Event rows joined to relevant KV pairs (restricted to columns referenced by the rule when provided).';\n",
    "\n",
    "-- ======================================================================\n",
    "-- 4) Fan out event_id â†’ individual check_id (many-to-many)\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_event_check_ids_mv AS\n",
    "SELECT\n",
    "  e.event_id,\n",
    "  cid AS check_id\n",
    "FROM dashboard_events_mv e\n",
    "LATERAL VIEW OUTER explode(e.check_id) c AS cid;\n",
    "\n",
    "COMMENT ON TABLE dashboard_event_check_ids_mv IS\n",
    "'Mapping of event_id to each check_id (1 row per check_id per event).';\n",
    "\n",
    "-- ======================================================================\n",
    "-- 5) Enrich events with rule metadata via check_id\n",
    "-- ======================================================================\n",
    "CREATE MATERIALIZED VIEW dashboard_events_enriched_mv AS\n",
    "SELECT\n",
    "  e.event_id,\n",
    "  e.severity,\n",
    "  e.log_id,\n",
    "  e.table_name,\n",
    "  e.run_config_name,\n",
    "  e.check_name,\n",
    "  ec.check_id                            AS check_id,\n",
    "  r.name                                 AS config_rule_name,\n",
    "  r.criticality                          AS config_criticality,\n",
    "  r.filter                               AS config_filter,\n",
    "  r.run_config_name                      AS config_run_config_name,\n",
    "  to_json(r.check)                       AS config_check_json,\n",
    "  to_json(r.check.arguments)             AS config_arguments_json,\n",
    "  e.function,\n",
    "  e.filter,\n",
    "  e.rule_columns,\n",
    "  e.message,\n",
    "  e.user_metadata,\n",
    "  e.run_time,\n",
    "  e.created_at,\n",
    "  e.pattern_fingerprint,\n",
    "  e.row_fp\n",
    "FROM dashboard_events_mv e\n",
    "LEFT JOIN dashboard_event_check_ids_mv ec\n",
    "  ON ec.event_id = e.event_id\n",
    "LEFT JOIN dq_dev.dqx.checks r\n",
    "  ON r.check_id = ec.check_id;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_enriched_mv IS\n",
    "'Events with per-check enrichment (joins dq_dev.dqx.checks via check_id). Includes arguments JSON for parameterized analysis.';\n",
    "\n",
    "-- ======================================================================\n",
    "-- 6) Common aggregations (materialized for speed)\n",
    "-- ======================================================================\n",
    "\n",
    "-- By day (use run_time when present, else created_at)\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_day_mv AS\n",
    "SELECT\n",
    "  date_trunc('day', COALESCE(run_time, created_at)) AS day,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY date_trunc('day', COALESCE(run_time, created_at));\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_day_mv IS\n",
    "'Daily counts of error/warn events. Uses run_time when present; otherwise created_at.';\n",
    "\n",
    "-- By table\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_table_mv AS\n",
    "SELECT\n",
    "  table_name,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY table_name;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_table_mv IS\n",
    "'Counts of error/warn events per table.';\n",
    "\n",
    "-- By check (issue name in the log; use *_enriched_mv for config.name)\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_check_mv AS\n",
    "SELECT\n",
    "  COALESCE(check_name, 'unknown')        AS check_name,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY COALESCE(check_name, 'unknown');\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_check_mv IS\n",
    "'Counts of error/warn events per check_name (from the log).';\n",
    "\n",
    "-- By run_config\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_run_config_mv AS\n",
    "SELECT\n",
    "  run_config_name,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events_mv\n",
    "GROUP BY run_config_name;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_run_config_mv IS\n",
    "'Counts of error/warn events per run_config_name.';\n",
    "\n",
    "-- By column (scoped event Ã— KV)\n",
    "CREATE MATERIALIZED VIEW dashboard_events_by_column_mv AS\n",
    "SELECT\n",
    "  column,\n",
    "  SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "  SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_event_kv_mv\n",
    "GROUP BY column;\n",
    "\n",
    "COMMENT ON TABLE dashboard_events_by_column_mv IS\n",
    "'Counts of error/warn events per column, scoped to rule columns when available.';\n",
    "\n",
    "-- Top error messages (dedup by message text)\n",
    "CREATE MATERIALIZED VIEW dashboard_top_error_messages_mv AS\n",
    "SELECT\n",
    "  message,\n",
    "  COUNT(*) AS error_events\n",
    "FROM dashboard_events_mv\n",
    "WHERE severity = 'ERROR'\n",
    "GROUP BY message\n",
    "ORDER BY error_events DESC;\n",
    "\n",
    "COMMENT ON TABLE dashboard_top_error_messages_mv IS\n",
    "'Most frequent error messages across all events.';"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7524721292978359,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_dashboard_dqx_checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
