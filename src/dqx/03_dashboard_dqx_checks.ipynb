{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e98fb36c-b673-4140-bf7f-8a226593588e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DQX Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31157eee-573f-4ada-8c55-22ebf177d561",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Databricks Labs DQX Version 0.8.0"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291fbe0f-3979-4077-b104-6ca0ade33c3c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python Environment"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50fc6614-ac81-4e6d-a3df-b1bc9dbb7da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DQX Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82090f6b-1313-4a32-a4bf-960bf386cb6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%databricks labs dqx open-dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61565af4-13a0-434a-a22e-b32284f2b644",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Open Databricks Labs DQX Dashboards"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext databricks_labs_dqx\n",
    "\n",
    "%databricks labs dqx open-dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d549530-f861-4d68-ac21-888f154b16eb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dqx_config.yaml"
    }
   },
   "outputs": [],
   "source": [
    "# Location Document Saved: C:\\Users\\gagn57943\\Documents\\dqx_config.yaml\n",
    "# -------------------------------------------------------------------------\n",
    "log_level: INFO\n",
    "version: 1\n",
    "\n",
    "run_configs:\n",
    "- name: default\n",
    "  quarantine_config:\n",
    "    location: dq_dev.dqx.generated_checks_log\n",
    "    format: delta\n",
    "    mode: append\n",
    "\n",
    "  checks_location: dq_dev.dqx.generated_checks_log\n",
    "\n",
    "  warehouse_id: \"ca5a45e27debab49\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a9ff683-d53e-4d33-8103-a022602ee2f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.labs.dqx.contexts.workspace import WorkspaceContext\n",
    "\n",
    "# Optional: make the link clickable in the notebook\n",
    "def _display_html_link(url: str, label: str = None):\n",
    "    try:\n",
    "        displayHTML(f'<a href=\"{url}\" target=\"_blank\">{label or url}</a>')\n",
    "    except Exception:\n",
    "        print(url)\n",
    "\n",
    "# Build the base link to the dashboards \"folder\" in your workspace\n",
    "ctx = WorkspaceContext(WorkspaceClient())\n",
    "dashboards_folder_link = f\"{ctx.installation.workspace_link('')}dashboards/\"\n",
    "\n",
    "print(\"Open a dashboard from this folder, then hit Refresh inside the dashboard:\")\n",
    "print(dashboards_folder_link)\n",
    "_display_html_link(dashboards_folder_link, \"Open DQX dashboards folder\")\n",
    "\n",
    "# (Optional) If you know a specific dashboard path (from the UI),\n",
    "# you can deep-link to it like this:\n",
    "# my_dash_relpath = \"dashboards/Shared/DQX/Quality Overview\"  # example path after you open the folder and copy link\n",
    "# my_dash_link = f\"{ctx.installation.workspace_link('')}{my_dash_relpath}\"\n",
    "# print(\"Direct dashboard link:\")\n",
    "# _display_html_link(my_dash_link, \"Open: DQX – Quality Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4440c58-8fd7-4252-a090-2cafca1d8c1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.labs.dqx.contexts.workspace import WorkspaceContext\n",
    "\n",
    "ctx = WorkspaceContext(WorkspaceClient())\n",
    "dashboards_folder_link = f\"{ctx.installation.workspace_link('')}dashboards/\"\n",
    "print(f\"Open a dashboard from the following folder and refresh it:\")\n",
    "print(dashboards_folder_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03ec41fd-686f-4025-9a28-20127a8c7992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Custom DQX Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "784f4a1f-63b0-4f6e-8f5f-d455d8f460f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Databricks SDK for Python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f2d5c2c-0faa-4183-8ee6-71b4eed5af6f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python Libraries"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f84301a-2d87-41eb-bc49-3d3d6a3e4056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Authoritative `dashboard_*` Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc783c37-55d8-41d8-b0d1-a4c2c3fa550e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DQX dashboard base & tiles (idempotent)\n",
    "USE CATALOG dq_dev;\n",
    "USE SCHEMA dqx;\n",
    "\n",
    "-- Clean\n",
    "DROP VIEW IF EXISTS dashboard_errors;\n",
    "DROP VIEW IF EXISTS dashboard_warnings;\n",
    "DROP VIEW IF EXISTS dashboard_events;\n",
    "DROP VIEW IF EXISTS dashboard_row_kv;\n",
    "DROP VIEW IF EXISTS dashboard_row_value_stats;\n",
    "DROP VIEW IF EXISTS dashboard_kpi;\n",
    "DROP VIEW IF EXISTS dashboard_error_patterns;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_day;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_check;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_table;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_column;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_run_config;\n",
    "DROP VIEW IF EXISTS dashboard_top_error_messages;\n",
    "DROP VIEW IF EXISTS dashboard_rules_catalog;\n",
    "DROP VIEW IF EXISTS dashboard_rules_affected;\n",
    "DROP VIEW IF EXISTS dashboard_rules_coverage;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1efd40-4475-4982-b1fb-0ea12893f4ca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Clean and Create Views for Dashboard Events"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DQX dashboard base & tiles (idempotent)\n",
    "USE CATALOG dq_dev;\n",
    "USE SCHEMA dqx;\n",
    "\n",
    "-- Clean\n",
    "DROP VIEW IF EXISTS dashboard_errors;\n",
    "DROP VIEW IF EXISTS dashboard_warnings;\n",
    "DROP VIEW IF EXISTS dashboard_events;\n",
    "DROP VIEW IF EXISTS dashboard_row_kv;\n",
    "DROP VIEW IF EXISTS dashboard_row_value_stats;\n",
    "DROP VIEW IF EXISTS dashboard_kpi;\n",
    "DROP VIEW IF EXISTS dashboard_error_patterns;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_day;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_check;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_table;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_column;\n",
    "DROP VIEW IF EXISTS dashboard_events_by_run_config;\n",
    "DROP VIEW IF EXISTS dashboard_top_error_messages;\n",
    "DROP VIEW IF EXISTS dashboard_rules_catalog;\n",
    "DROP VIEW IF EXISTS dashboard_rules_affected;\n",
    "DROP VIEW IF EXISTS dashboard_rules_coverage;\n",
    "\n",
    "-- 1) Events from arrays (stable event_id via posexplode)\n",
    "CREATE OR REPLACE VIEW dashboard_errors AS\n",
    "SELECT\n",
    "  l.log_id, l.table_name, l.run_config_name,\n",
    "  e.name AS check_name, e.message, e.function, e.filter,\n",
    "  e.run_time, e.user_metadata, e.columns,\n",
    "  l.created_at,\n",
    "  l._errors_fingerprint, l.row_snapshot_fingerprint,\n",
    "  p.pos AS err_pos,\n",
    "  sha2(concat(l.log_id, ':E:', cast(p.pos AS STRING)), 256) AS event_id\n",
    "FROM dq_dev.dqx.checks_log l\n",
    "LATERAL VIEW OUTER posexplode(_errors) p AS pos, e;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_warnings AS\n",
    "SELECT\n",
    "  l.log_id, l.table_name, l.run_config_name,\n",
    "  w.name AS check_name, w.message, w.function, w.filter,\n",
    "  w.run_time, w.user_metadata, w.columns,\n",
    "  l.created_at,\n",
    "  l._warnings_fingerprint, l.row_snapshot_fingerprint,\n",
    "  p.pos AS warn_pos,\n",
    "  sha2(concat(l.log_id, ':W:', cast(p.pos AS STRING)), 256) AS event_id\n",
    "FROM dq_dev.dqx.checks_log l\n",
    "LATERAL VIEW OUTER posexplode(_warnings) p AS pos, w;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_events AS\n",
    "SELECT 'ERROR' AS severity, * EXCEPT(err_pos) FROM dashboard_errors\n",
    "UNION ALL\n",
    "SELECT 'WARN'  AS severity, * EXCEPT(warn_pos) FROM dashboard_warnings;\n",
    "\n",
    "-- 2) Row snapshot → KV + quick value stats\n",
    "CREATE OR REPLACE VIEW dashboard_row_kv AS\n",
    "SELECT\n",
    "  l.log_id, l.table_name, l.run_config_name, l.created_at,\n",
    "  kv.column AS column, kv.value AS value,\n",
    "  CASE WHEN kv.value IS NULL THEN TRUE ELSE FALSE END                                    AS is_null,\n",
    "  CASE WHEN kv.value IS NOT NULL AND length(trim(kv.value)) = 0 THEN TRUE ELSE FALSE END AS is_empty,\n",
    "  CASE WHEN TRY_CAST(kv.value AS DOUBLE) = 0 THEN TRUE ELSE FALSE END                    AS is_zero\n",
    "FROM dq_dev.dqx.checks_log l\n",
    "LATERAL VIEW OUTER explode(row_snapshot) s AS kv;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_row_value_stats AS\n",
    "SELECT\n",
    "  log_id,\n",
    "  SUM(CASE WHEN is_null  THEN 1 ELSE 0 END) AS null_count,\n",
    "  SUM(CASE WHEN is_empty THEN 1 ELSE 0 END) AS empty_count,\n",
    "  SUM(CASE WHEN is_zero  THEN 1 ELSE 0 END) AS zero_count\n",
    "FROM dashboard_row_kv\n",
    "GROUP BY log_id;\n",
    "\n",
    "-- 3) KPIs (rows vs events; uniqueness; recency)\n",
    "CREATE OR REPLACE VIEW dashboard_kpi AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    COUNT(*)                                                   AS rows_with_any_issue,\n",
    "    SUM(CASE WHEN size(_errors)  > 0 THEN 1 ELSE 0 END)       AS rows_with_errors,\n",
    "    SUM(CASE WHEN size(_warnings)> 0 THEN 1 ELSE 0 END)       AS rows_with_warnings,\n",
    "    SUM(CASE WHEN size(_errors)=0 AND size(_warnings)>0 THEN 1 ELSE 0 END) AS rows_warn_only,\n",
    "    SUM(CASE WHEN size(_errors)>0 AND size(_warnings)>0 THEN 1 ELSE 0 END) AS rows_both,\n",
    "    COUNT(DISTINCT row_snapshot_fingerprint)                   AS unique_rows_fingerprint,\n",
    "    COUNT(DISTINCT _errors_fingerprint)                        AS unique_error_patterns,\n",
    "    COUNT(DISTINCT _warnings_fingerprint)                      AS unique_warning_patterns,\n",
    "    MIN(created_at)                                            AS first_ingest_at,\n",
    "    MAX(created_at)                                            AS last_ingest_at\n",
    "  FROM dq_dev.dqx.checks_log\n",
    "),\n",
    "evt AS (\n",
    "  SELECT\n",
    "    SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "    SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "  FROM dashboard_events\n",
    ")\n",
    "SELECT\n",
    "  b.*,\n",
    "  e.error_events,\n",
    "  e.warning_events,\n",
    "  ROUND(e.error_events / NULLIF(b.rows_with_any_issue,0), 3)  AS avg_errors_per_row,\n",
    "  ROUND(e.warning_events / NULLIF(b.rows_with_any_issue,0), 3) AS avg_warnings_per_row\n",
    "FROM base b CROSS JOIN evt e;\n",
    "\n",
    "-- 4) Patterns & breakdowns\n",
    "CREATE OR REPLACE VIEW dashboard_error_patterns AS\n",
    "SELECT\n",
    "  e._errors_fingerprint                AS error_pattern,\n",
    "  COUNT(DISTINCT e.log_id)             AS rows_hit,\n",
    "  ANY_VALUE(e.table_name)              AS sample_table,\n",
    "  ANY_VALUE(e.run_config_name)         AS sample_run_config,\n",
    "  ANY_VALUE(e.check_name)              AS sample_check_name,\n",
    "  ANY_VALUE(e.message)                 AS sample_message\n",
    "FROM dashboard_errors e\n",
    "GROUP BY e._errors_fingerprint\n",
    "ORDER BY rows_hit DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_events_by_day AS\n",
    "SELECT date_trunc('day', run_time) AS day,\n",
    "       SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "       SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events\n",
    "GROUP BY date_trunc('day', run_time)\n",
    "ORDER BY day;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_events_by_check AS\n",
    "SELECT COALESCE(check_name,'unknown') AS check_name,\n",
    "       SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "       SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events\n",
    "GROUP BY COALESCE(check_name,'unknown')\n",
    "ORDER BY error_events DESC, warning_events DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_events_by_table AS\n",
    "SELECT table_name,\n",
    "       SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "       SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events\n",
    "GROUP BY table_name\n",
    "ORDER BY error_events DESC, warning_events DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_events_by_column AS\n",
    "SELECT col AS column,\n",
    "       SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "       SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events\n",
    "LATERAL VIEW OUTER explode(columns) c AS col\n",
    "GROUP BY col\n",
    "ORDER BY error_events DESC, warning_events DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_events_by_run_config AS\n",
    "SELECT run_config_name,\n",
    "       SUM(CASE WHEN severity='ERROR' THEN 1 ELSE 0 END) AS error_events,\n",
    "       SUM(CASE WHEN severity='WARN'  THEN 1 ELSE 0 END) AS warning_events\n",
    "FROM dashboard_events\n",
    "GROUP BY run_config_name\n",
    "ORDER BY error_events DESC, warning_events DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_top_error_messages AS\n",
    "SELECT message, COUNT(*) AS error_events\n",
    "FROM dashboard_errors\n",
    "GROUP BY message\n",
    "ORDER BY error_events DESC;\n",
    "\n",
    "-- 5) Rule coverage (adjust FQN if your rules live elsewhere)\n",
    "CREATE OR REPLACE VIEW dashboard_rules_catalog AS\n",
    "SELECT check_id, name, criticality, table_name, run_config_name\n",
    "FROM dq_dev.dqx.checks_log;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_rules_affected AS\n",
    "SELECT cid AS check_id, COUNT(*) AS rows_hit\n",
    "FROM dq_dev.dqx.checks_log\n",
    "LATERAL VIEW OUTER explode(check_id) t AS cid\n",
    "GROUP BY cid\n",
    "ORDER BY rows_hit DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW dashboard_rules_coverage AS\n",
    "SELECT\n",
    "  c.check_id, c.name, c.criticality, c.table_name, c.run_config_name,\n",
    "  COALESCE(a.rows_hit, 0) AS rows_hit,\n",
    "  CASE WHEN a.check_id IS NULL THEN FALSE ELSE TRUE END AS ever_fired\n",
    "FROM dashboard_rules_catalog c\n",
    "LEFT JOIN dashboard_rules_affected a USING (check_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee753c3-ea94-469e-bcf8-7b6f506d2497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lakeview DQX Dashboard via SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f82deb-142d-4949-9694-a4f1852fa28d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Lakeview dashboard from repo JSON; publish; schedule; export snapshot\n",
    "# Run in Databricks (no local tooling required).\n",
    "\n",
    "%pip install -q databricks-sdk\n",
    "dbutils.library.restartPython()\n",
    "\n",
    "import json, os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.dashboards import (\n",
    "    Dashboard as LvDashboard,\n",
    "    Schedule, ScheduleTrigger, ScheduleTriggerType,\n",
    "    Interval, IntervalUnit,\n",
    ")\n",
    "\n",
    "# --- config ---\n",
    "WAREHOUSE_ID = \"ca5a45e27debab49\"\n",
    "SCHEDULE_EVERY_MIN = 30\n",
    "DISPLAY_NAME = \"DQX – Quality Overview\"\n",
    "# Use Shared or your user folder:\n",
    "PARENT_PATH = \"/Users/levi.gagne@claconnect.com/DQX\"  # e.g., \"/Users/levi.gagne@claconnect.com/DQX\"\n",
    "\n",
    "# Path to your repo JSON (relative to this notebook's folder)\n",
    "JSON_REL_PATH = \"dashboards/DQX_Overview.lvdash.json\"\n",
    "\n",
    "# --- resolve repo file to /Workspace path ---\n",
    "nb_path = dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "repo_dir = os.path.dirname(nb_path)\n",
    "json_ws_path = f\"{repo_dir}/{JSON_REL_PATH}\".replace(\"//\", \"/\")\n",
    "json_local = \"/Workspace\" + json_ws_path  # filesystem path to open()\n",
    "\n",
    "print(f\"Reading dashboard JSON: {json_local}\")\n",
    "with open(json_local, \"r\", encoding=\"utf-8\") as f:\n",
    "    serialized = f.read()\n",
    "\n",
    "# Optional templating: replace placeholder with actual warehouse id\n",
    "serialized = serialized.replace(\"{{WAREHOUSE_ID}}\", WAREHOUSE_ID)\n",
    "\n",
    "# Validate minimal fields\n",
    "try:\n",
    "    _ = json.loads(serialized)\n",
    "except json.JSONDecodeError as e:\n",
    "    raise ValueError(f\"Invalid JSON in {json_local}: {e}\")\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Ensure parent folder\n",
    "try:\n",
    "    w.workspace.get_status(PARENT_PATH)\n",
    "except Exception:\n",
    "    w.workspace.mkdirs(PARENT_PATH)\n",
    "\n",
    "# Create dashboard from serialized JSON (clean create; no UI)\n",
    "dash = w.lakeview.create(LvDashboard(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    warehouse_id=WAREHOUSE_ID,           # default warehouse\n",
    "    parent_path=PARENT_PATH,\n",
    "    serialized_dashboard=serialized      # your definition\n",
    "))\n",
    "DASHBOARD_ID = dash.dashboard_id\n",
    "print(\"dashboard_id:\", DASHBOARD_ID)\n",
    "\n",
    "# Publish (so schedules/subscriptions can attach)\n",
    "w.lakeview.publish(DASHBOARD_ID)\n",
    "\n",
    "# Attach a refresh schedule\n",
    "schedule = Schedule(\n",
    "    display_name=f\"Every {SCHEDULE_EVERY_MIN} minutes\",\n",
    "    trigger=ScheduleTrigger(\n",
    "        trigger_type=ScheduleTriggerType.INTERVAL,\n",
    "        interval=Interval(unit=IntervalUnit.MINUTE, frequency=SCHEDULE_EVERY_MIN),\n",
    "    ),\n",
    "    paused=False,\n",
    ")\n",
    "sched = w.lakeview.create_schedule(DASHBOARD_ID, schedule)\n",
    "print(\"schedule_id:\", sched.schedule.schedule_id)\n",
    "\n",
    "# Print URL\n",
    "base = w.config.host.rstrip(\"/\")\n",
    "url = f\"{base}/dashboardsv3/{DASHBOARD_ID}\"\n",
    "print(\"dashboard url:\", url)\n",
    "\n",
    "# Export server-enriched JSON snapshot (what the workspace stores)\n",
    "server_def = w.lakeview.get(DASHBOARD_ID)\n",
    "snapshot = server_def.serialized_dashboard or \"\"\n",
    "snap_path = \"/Workspace\" + f\"{repo_dir}/dashboards/DQX_Overview.snapshot.lvdash.json\"\n",
    "with open(snap_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(snapshot)\n",
    "print(\"snapshot written:\", snap_path)\n",
    "\n",
    "# Tip: commit dashboards/DQX_Overview.snapshot.lvdash.json to Git as the source of truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "179c1675-a23b-4090-84d3-09d96cc2fdad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7524721292978359,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_dashboard_dqx_checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
