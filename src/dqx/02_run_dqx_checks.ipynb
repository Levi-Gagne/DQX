{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21cb849b-098d-4a4e-9520-f09f2c3350e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Run DQX Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0adb6f05-ca34-4a4d-a555-cf290250c755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "eb4cf86c-394e-4979-bd9f-2c58a548cc75",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "RUNBOOK"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Runbook — 02_run_dqx_checks (Run DQX Checks)\n",
    "\n",
    "**Purpose**  \n",
    "Execute Databricks Labs DQX rules from the config table, write a row‑level results log, and produce lightweight rollups for dashboards.\n",
    "\n",
    "---\n",
    "\n",
    "## At a glance\n",
    "- **Notebook:** `02_run_dqx_checks`\n",
    "- **Engine:** `databricks-labs-dqx==0.8.x`\n",
    "- **Reads:** rules from `dq_{env}.dqx.checks_log` (Delta)\n",
    "- **Writes:**\n",
    "  - **Row log:** `dqx_checks_log_table_name` (Delta, one row per flagged source row)\n",
    "  - **Summary (by rule):** `dq_dev.dqx.checks_log_summary_by_rule` (append)\n",
    "  - **Summary (by table):** `dq_dev.dqx.checks_log_summary_by_table` (overwrite)\n",
    "- **Key behavior:** embeds `check_id` **inside each issue element** of `_errors`/`_warnings` (no top‑level `check_id` column). Deterministic `log_id` prevents accidental duplicates within a run.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- Unity Catalog schemas exist and you have permission to **read source tables** and **write** to the targets above.\n",
    "- Rules have been loaded by **01_load_dqx_checks** into the checks config table.\n",
    "- Cluster/SQL warehouse with Delta support. The notebook enables `spark.databricks.delta.schema.autoMerge.enabled=true` for nested struct evolution.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs & Config\n",
    "YAML at `resources/dqx_config.yaml` (or your path) must define:\n",
    "```yaml\n",
    "dqx_checks_config_table_name: dq_dev.dqx.checks           # rules table (from loader)\n",
    "dqx_checks_log_table_name:    dq_dev.dqx.checks_log       # results (row log)\n",
    "run_config_name:                                          # named run configs (RCs)\n",
    "  nightly:\n",
    "    output_config:\n",
    "      mode: overwrite                                     # overwrite|append\n",
    "      options: {}                                         # any DataFrameWriter options\n",
    "  ad_hoc:\n",
    "    output_config:\n",
    "      mode: append\n",
    "      options: {}\n",
    "```\n",
    "\n",
    "**Rules selection per RC:** active rules where `run_config_name == <RC>` are loaded from the checks table.\n",
    "\n",
    "---\n",
    "\n",
    "## How to run\n",
    "Minimal usage in a cell:\n",
    "```python\n",
    "# One‑time per cluster session\n",
    "# %pip install databricks-labs-dqx==0.8.0\n",
    "# dbutils.library.restartPython()\n",
    "\n",
    "run_checks(\n",
    "    dqx_cfg_yaml=\"resources/dqx_config.yaml\",\n",
    "    created_by=\"AdminUser\",\n",
    "    time_zone=\"America/Chicago\",\n",
    "    exclude_cols=None,            # optional: columns to exclude from row_snapshot\n",
    "    coercion_mode=\"strict\"        # \"permissive\" or \"strict\" argument coercion\n",
    ")\n",
    "```\n",
    "\n",
    "**Parameters**\n",
    "- `dqx_cfg_yaml` – path to the YAML above.\n",
    "- `created_by` – audit field written to the row log.\n",
    "- `time_zone` – for banners/printing only.\n",
    "- `exclude_cols` – columns to omit from `row_snapshot` (e.g., large blobs).\n",
    "- `coercion_mode` – how strictly to coerce stringified rule arguments (`strict` recommended).\n",
    "\n",
    "---\n",
    "\n",
    "## What it does (flow)\n",
    "1. **Environment banner** and YAML load.  \n",
    "2. **Ensure row‑log table exists** (creates empty Delta table with schema & comments if missing).  \n",
    "3. For each **run config (RC)** in YAML:  \n",
    "   a. **Load active rules** for that RC from the checks table; JIT‑coerce argument types; validate with `DQEngine`. Invalid rules are skipped (isolated).  \n",
    "   b. **Group by table**, read each source table, and call `DQEngine.apply_checks_by_metadata`. If a batch fails, the runner tests rules individually and drops offenders.  \n",
    "   c. **Project row hits** to the row‑log schema, computing:\n",
    "      - `row_snapshot` = `[{\"column\",\"value\"}...]` over non‑reserved columns (stringified)  \n",
    "      - Fingerprints for `_errors`, `_warnings`, and `row_snapshot`  \n",
    "      - Deterministic `log_id = sha256(table_name, run_config_name, row_snapshot_fp, _errors_fp, _warnings_fp)`  \n",
    "   d. **Embed `check_id`** into each issue element (errors & warnings) by matching `(table, run_config_name, rule name, filter)`.  \n",
    "   e. **Write row log** to `dqx_checks_log_table_name` using RC’s `output_config` (default `overwrite`).  \n",
    "   f. **Summaries:** display per‑table rollups; build **by‑rule** counts (including zero‑hit rules) and append to `dq_dev.dqx.checks_log_summary_by_rule`.  \n",
    "4. **Grand rollup (all RCs)** is written to `dq_dev.dqx.checks_log_summary_by_table` (overwrite).  \n",
    "5. **Final banner** prints total rows written.\n",
    "\n",
    "---\n",
    "\n",
    "## Row‑Log schema (essential fields)\n",
    "- `log_id` *(PK)* – deterministic hash; ensures idempotency within a run.  \n",
    "- `table_name`, `run_config_name` – lineage.  \n",
    "- `_errors`, `_warnings` – arrays of issue structs:  \n",
    "  `{ name, message, columns[], filter, function, run_time, user_metadata, check_id }`  \n",
    "- `_errors_fingerprint`, `_warnings_fingerprint` – order/column‑order insensitive digests.  \n",
    "- `row_snapshot` – array of `{column, value}` (stringified).  \n",
    "- `row_snapshot_fingerprint` – digest included in `log_id`.  \n",
    "- `created_by`, `created_at`, `updated_by`, `updated_at` – audit.\n",
    "\n",
    "> **Note:** There is **no** top‑level `check_id` column; IDs live **inside** each issue element.\n",
    "\n",
    "---\n",
    "\n",
    "## Operational tips\n",
    "- **Write mode per RC**: control idempotency via YAML (`overwrite` recommended for scheduled runs; `append` for incremental scenarios).  \n",
    "- **Schema evolution**: if upgrading from a version without `issue.check_id`, the runner sets `autoMerge=true` to evolve arrays of structs in place.  \n",
    "- **Performance**: large tables can be slow—filter with rule‑level `filter` predicates in the checks table; consider running by table RCs.  \n",
    "- **Dashboards**: the downstream views in your dashboard should explode `_errors`/`_warnings` and join by embedded `check_id` when needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "- **“no checks loaded”** for an RC → ensure checks table has `active=true` and exact `run_config_name` match.  \n",
    "- **Validation failures** → the runner will isolate bad rules and continue; check notebook output for offending rules (JSON logged). Fix the rule in YAML and re‑load with the loader.  \n",
    "- **Duplicate rows in append mode** → `log_id` is deterministic for the same row snapshot & issues; if inputs change (e.g., timestamps), duplicates are expected. Prefer `overwrite` for repeatable runs.  \n",
    "- **Missing `check_id` in issues** → verify rule names/filters/table names in checks table match the issues; embedding derives IDs by `(table_key, run_config_name, rule name, filter)`.\n",
    "\n",
    "---\n",
    "\n",
    "## Verification queries\n",
    "```sql\n",
    "-- Row log rows by run config\n",
    "SELECT run_config_name, COUNT(*) AS rows\n",
    "FROM dq_dev.dqx.checks_log\n",
    "GROUP BY run_config_name\n",
    "ORDER BY rows DESC;\n",
    "\n",
    "-- Any issue elements missing check_id?\n",
    "SELECT SUM(size(filter(_errors,   x -> x.check_id IS NULL))) AS errors_missing_id,\n",
    "       SUM(size(filter(_warnings, x -> x.check_id IS NULL))) AS warnings_missing_id\n",
    "FROM dq_dev.dqx.checks_log;\n",
    "\n",
    "-- Latest summaries\n",
    "SELECT * FROM dq_dev.dqx.checks_log_summary_by_rule   ORDER BY run_config_name, rows_flagged DESC;\n",
    "SELECT * FROM dq_dev.dqx.checks_log_summary_by_table  ORDER BY run_config_name, table_name;\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3ef14342-0f6c-4cc7-9bb2-387e0759853c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "FLOW"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "START: run_checks_loader(spark, cfg, *, notebook_idx, exclude_cols=None, coercion_mode=\"strict\")\n",
    "|\n",
    "|-- 0. Bootstrap / imports\n",
    "|     |-- add_src_to_sys_path() → make `framework_utils` importable\n",
    "|     |-- from framework_utils: Color, show_notebook_env, show_df, display_section, ProjectConfig, TableWriter, table_exists\n",
    "|     |-- from databricks.labs.dqx.engine import DQEngine\n",
    "|\n",
    "|-- 1. Resolve config + target tables\n",
    "|     |-- nb = cfg.notebook(notebook_idx)\n",
    "|     |-- checks_table = notebooks.notebook_1.targets.target_table_1 (catalog.schema.table)\n",
    "|     |-- t1 = row-level log target (required)\n",
    "|     |-- t2 = summary-by-rule target (optional if defined)\n",
    "|     |-- t3 = summary-by-table target (optional if defined)\n",
    "|\n",
    "|-- 2. Ensure destination Delta tables exist (TableWriter)\n",
    "|     |-- if not table_exists(t1): create with CHECKS_LOG_STRUCT (+ table comment/tags/PK/partition if provided)\n",
    "|     |-- if t2 and not table_exists(t2): create with CHECKS_LOG_SUMMARY_BY_RULE_STRUCT\n",
    "|     |-- if t3 and not table_exists(t3): create with CHECKS_LOG_SUMMARY_BY_TABLE_STRUCT\n",
    "|\n",
    "|-- 3. Init DQX + banner counts\n",
    "|     |-- dq = DQEngine(WorkspaceClient())\n",
    "|     |-- checks_table_total = COUNT(*) FROM checks_table WHERE active = TRUE  (try/except → -1 on failure)\n",
    "|     |-- grand_total = 0\n",
    "|     |-- all_tbl_summaries = []\n",
    "|\n",
    "|-- 4. Discover run configs (active only)\n",
    "|     |-- rc_names = DISTINCT run_config_name FROM checks_table WHERE active = TRUE (non-null)\n",
    "|\n",
    "|-- 5. For each rc_name in sorted(rc_names):\n",
    "|     |-- DISPLAY \"Run config: {rc_name}\"\n",
    "|\n",
    "|     |-- 5.1 Load + validate checks for this run config\n",
    "|     |     |-- _load_checks_from_table_as_dicts(spark, checks_table, rc_name, coercion_mode)\n",
    "|     |     |     |-- SELECT active=TRUE, columns: table_name, name, criticality, filter, run_config_name, user_metadata, check\n",
    "|     |     |     |-- JIT-arg coercion via _coerce_arguments(...) using EXPECTED spec (strict by default)\n",
    "|     |     |     |-- DQEngine.validate_checks() (batch). If invalid: re-validate per rule and drop the bad ones\n",
    "|     |     |     |-- returns: by_tbl: Dict[table_name → [rule dict]], coerced_count, skipped_invalid_count\n",
    "|     |     |-- PRINT summary: checks_table_total, loaded, coerced, skipped_invalid\n",
    "|     |     |-- if loaded == 0: continue\n",
    "|\n",
    "|     |-- 5.2 Apply rules per table (with isolation on failures)\n",
    "|     |     |-- init: out_batches=[], rc_tbl_summaries=[], rc_rule_hit_parts=[], table_row_counts={}, processed_tables=[]\n",
    "|     |     |-- for each tbl, tbl_rules in by_tbl (sorted):\n",
    "|     |           |-- src = spark.read.table(tbl) (try/except → continue if read fails)\n",
    "|     |           |-- (annot, bad_rules) = _apply_rules_isolating_failures(dq, src, tbl, tbl_rules)\n",
    "|     |           |     |-- try batch apply; on failure: probe each rule; keep good subset; collect bad(name,msg)\n",
    "|     |           |-- if annot is None:\n",
    "|     |           |     |-- if bad_rules: DISPLAY a \"Skipped rules\" DataFrame with reasons\n",
    "|     |           |     |-- continue\n",
    "|     |           |-- total_rows = annot.count(); table_row_counts[tbl] = total_rows; processed_tables += [tbl]\n",
    "|     |           |-- summary_row = _summarize_table(annot, tbl)  # counts rows with error/warn/any + distinct rules fired\n",
    "|     |           |-- rc_tbl_summaries += [summary_row]; all_tbl_summaries += [Row(run_config_name=rc_name, **summary_row)]\n",
    "|     |           |-- rc_rule_hit_parts += [_rules_hits_for_table(annot, tbl)]  # per-rule row counts (error|warning)\n",
    "|     |           |-- row_hits_df = _project_row_hits(\n",
    "|     |           |       annot, tbl, rc_name, created_by=\"AdminUser\", exclude_cols\n",
    "|     |           |   )\n",
    "|     |           |   |-- Produces RAW arrays _errors/_warnings (no check_id yet)\n",
    "|     |           |   |-- row_snapshot (non-reserved cols), row_snapshot_fingerprint\n",
    "|     |           |   |-- _errors/_warnings normalized & fingerprinted (order-insensitive)\n",
    "|     |           |   |-- log_id = sha256(tbl || rc_name || row_snapshot_fp || _errors_fp || _warnings_fp)\n",
    "|     |           |-- if row_hits_df has rows: out_batches += [row_hits_df]\n",
    "|\n",
    "|     |-- 5.3 Show per-RC summary-by-table\n",
    "|     |     |-- if rc_tbl_summaries: DISPLAY DataFrame(order by table_name)\n",
    "|\n",
    "|     |-- 5.4 Build + (optionally) write summary-by-rule (t2)\n",
    "|     |     |-- if rc_rule_hit_parts and t2:\n",
    "|     |           |-- rules_all = UNION rc_rule_hit_parts\n",
    "|     |           |-- cfg_rules = DISTINCT (table_name, rule_name=name, severity=warning if criticality in {warn,warning} else error)\n",
    "|     |           |-- counts = rules_all GROUP BY (table_name, name, severity) SUM(rows_flagged) → rename name→rule_name\n",
    "|     |           |-- full_rules = cfg_rules LEFT JOIN counts (NULL→0)\n",
    "|     |           |-- totals_df = table_row_counts → (table_name, table_total_rows)\n",
    "|     |           |-- full_rules += pct_of_table_rows = rows_flagged / table_total_rows (0 if unknown)\n",
    "|     |           |-- DISPLAY full_rules (ordered: rows_flagged desc, table asc, rule asc)\n",
    "|     |           |-- WRITE full_rules.withColumn(\"run_config_name\", rc_name)\n",
    "|     |                 → saveAsTable(t2.full_table_name()) with t2.write.{format,mode,options}\n",
    "|\n",
    "|     |-- 5.5 Row-level log write (t1)\n",
    "|     |     |-- if out_batches is empty:\n",
    "|     |     |     |-- PRINT \"[rc_name] no row-level hits.\" ; continue\n",
    "|     |     |-- out = UNION(out_batches)\n",
    "|     |     |-- out = _embed_issue_check_ids(out, checks_table)\n",
    "|     |     |   |-- Join against checks_table (active) on (run_config_name, normalized rule name, normalized filter, flexible table keys)\n",
    "|     |     |   |-- Converts RAW issue arrays → WITH-ID arrays (ISSUE_WITH_ID_STRUCT); fills check_id\n",
    "|     |     |-- Enforce PK idempotency:\n",
    "|     |     |   |-- pk_cols = list(t1.primary_key)\n",
    "|     |     |   |-- if duplicates on pk_cols → raise RuntimeError\n",
    "|     |     |   |-- dropDuplicates(pk_cols)\n",
    "|     |     |-- tw.write_df(out.select(CHECKS_LOG_STRUCT fields)) → t1.full_table_name()\n",
    "|     |     |   |-- uses t1.write.{mode,format,options}\n",
    "|     |     |-- rows = out.count(); grand_total += rows; PRINT wrote rows → t1.fqn\n",
    "|\n",
    "|     |-- 5.6 Update summary-by-table (t3) after each RC\n",
    "|     |     |-- if t3:\n",
    "|     |           |-- grand_df = DataFrame(all_tbl_summaries)  # includes run_config_name\n",
    "|     |           |-- Align schema to target; WRITE with t3.write.{format,mode,options} → t3.full_table_name()\n",
    "|\n",
    "|-- 6. Final banner\n",
    "|     |-- DISPLAY \"Grand total\"\n",
    "|     |-- PRINT \"TOTAL rows written: {grand_total}\" (with Color styling)\n",
    "|\n",
    "END: run_checks_loader  → returns {\"results_table\", \"grand_total_rows\", \"checks_table\", \"notebook_idx\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c0227b43-6cde-4c98-822e-17ecaeffcb84",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TARGET TABLES"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# dq_{env}.dqx.checks_log\n",
    "CHECKS_LOG_SCHEMA = T.StructType([\n",
    "    T.StructField(\"log_id\",                      T.StringType(),  False),  # PK (deterministic)\n",
    "    # (no top-level check_id)\n",
    "    T.StructField(\"table_name\",                  T.StringType(),  False),\n",
    "    T.StructField(\"run_config_name\",             T.StringType(),  False),\n",
    "\n",
    "    # _errors (array of issue structs; includes check_id inside each element)\n",
    "    T.StructField(\"_errors\", T.ArrayType(T.StructType([\n",
    "        T.StructField(\"name\",          T.StringType(), True),\n",
    "        T.StructField(\"message\",       T.StringType(), True),\n",
    "        T.StructField(\"columns\",       T.ArrayType(T.StringType()), True),\n",
    "        T.StructField(\"filter\",        T.StringType(), True),\n",
    "        T.StructField(\"function\",      T.StringType(), True),\n",
    "        T.StructField(\"run_time\",      T.TimestampType(), True),\n",
    "        T.StructField(\"user_metadata\", T.MapType(T.StringType(), T.StringType()), True),\n",
    "        T.StructField(\"check_id\",      T.StringType(), True),\n",
    "    ])), False),\n",
    "    T.StructField(\"_errors_fingerprint\",         T.StringType(),  False),\n",
    "\n",
    "    # _warnings (array of issue structs; includes check_id inside each element)\n",
    "    T.StructField(\"_warnings\", T.ArrayType(T.StructType([\n",
    "        T.StructField(\"name\",          T.StringType(), True),\n",
    "        T.StructField(\"message\",       T.StringType(), True),\n",
    "        T.StructField(\"columns\",       T.ArrayType(T.StringType()), True),\n",
    "        T.StructField(\"filter\",        T.StringType(), True),\n",
    "        T.StructField(\"function\",      T.StringType(), True),\n",
    "        T.StructField(\"run_time\",      T.TimestampType(), True),\n",
    "        T.StructField(\"user_metadata\", T.MapType(T.StringType(), T.StringType()), True),\n",
    "        T.StructField(\"check_id\",      T.StringType(), True),\n",
    "    ])), False),\n",
    "    T.StructField(\"_warnings_fingerprint\",       T.StringType(),  False),\n",
    "\n",
    "    T.StructField(\"row_snapshot\", T.ArrayType(T.StructType([\n",
    "        T.StructField(\"column\",        T.StringType(), False),\n",
    "        T.StructField(\"value\",         T.StringType(), True),\n",
    "    ])), False),\n",
    "    T.StructField(\"row_snapshot_fingerprint\",    T.StringType(),  False),\n",
    "\n",
    "    T.StructField(\"created_by\",                  T.StringType(),  False),\n",
    "    T.StructField(\"created_at\",                  T.TimestampType(), False),\n",
    "    T.StructField(\"updated_by\",                  T.StringType(),  True),\n",
    "    T.StructField(\"updated_at\",                  T.TimestampType(), True),\n",
    "])\n",
    "\n",
    "########################################################################\n",
    "# dq_{env}.dqx.checks_log_summary_by_table\n",
    "CHECKS_LOG_SUMMARY_BY_TABLE_SCHEMA = T.StructType([\n",
    "    T.StructField(\"run_config_name\",   T.StringType(),  False),\n",
    "    T.StructField(\"table_name\",        T.StringType(),  False),\n",
    "    T.StructField(\"rule_name\",         T.StringType(),  False),\n",
    "    T.StructField(\"severity\",          T.StringType(),  False),  # 'error' | 'warning'\n",
    "    T.StructField(\"rows_flagged\",      T.LongType(),    False),\n",
    "    T.StructField(\"table_total_rows\",  T.LongType(),    True),\n",
    "    T.StructField(\"pct_of_table_rows\", T.DoubleType(),  False),\n",
    "])\n",
    "\n",
    "########################################################################\n",
    "# dq_{env}.dqx.checks_log_summary_by_rule\n",
    "CHECKS_LOG_SUMMARY_BY_TABLE_SCHEMA = T.StructType([\n",
    "    T.StructField(\"run_config_name\",          T.StringType(), False),\n",
    "    T.StructField(\"table_name\",               T.StringType(), False),\n",
    "    T.StructField(\"table_total_rows\",         T.LongType(),   False),\n",
    "    T.StructField(\"table_total_error_rows\",   T.LongType(),   False),\n",
    "    T.StructField(\"table_total_warning_rows\", T.LongType(),   False),\n",
    "    T.StructField(\"total_flagged_rows\",       T.LongType(),   False),\n",
    "    T.StructField(\"distinct_rules_fired\",     T.IntegerType(), False),\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbf186ca-3376-499b-a05c-0c62e6b841c9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DQX Check Result Schema"
    }
   },
   "outputs": [],
   "source": [
    "#NOTE: https://github.com/databrickslabs/dqx/blob/v0.9.0/src/databricks/labs/dqx/schema/dq_result_schema.py\n",
    "\"\"\"\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, StringType, TimestampType, MapType\n",
    "\n",
    "dq_result_item_schema = StructType(\n",
    "    [\n",
    "        StructField(\"name\", StringType(), nullable=True),\n",
    "        StructField(\"message\", StringType(), nullable=True),\n",
    "        StructField(\"columns\", ArrayType(StringType()), nullable=True),\n",
    "        StructField(\"filter\", StringType(), nullable=True),\n",
    "        StructField(\"function\", StringType(), nullable=True),\n",
    "        StructField(\"run_time\", TimestampType(), nullable=True),\n",
    "        StructField(\"user_metadata\", MapType(StringType(), StringType()), nullable=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dq_result_schema = ArrayType(dq_result_item_schema)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a78104a0-59e2-4002-b6f1-99c62f231325",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dd5ff1b-2ce1-413f-b59b-68869d78ee41",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install DQX Package"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51cc1ec0-88bc-4913-bb3d-480b8f9928ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python Environment"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5807fa6d-2e61-45f8-bb2a-6636dfd7438f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Main"
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook: 02_run_dqx_checks\n",
    "# Purpose: Run DQX checks and write row-level logs + summaries\n",
    "# Requires: databricks-labs-dqx==0.8.x\n",
    "\n",
    "from __future__ import annotations\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame, Row, functions as F, types as T\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "\n",
    "from resources.dqx_functions_0_8_0 import EXPECTED as _EXPECTED\n",
    "\n",
    "def add_src_to_sys_path(src_dir=\"src\", sentinel=\"framework_utils\", max_levels=12):\n",
    "    start = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "    p = start\n",
    "    for _ in range(max_levels):\n",
    "        cand = p / src_dir\n",
    "        if (cand / sentinel).exists():\n",
    "            s = str(cand.resolve())\n",
    "            if s not in sys.path:\n",
    "                sys.path.insert(0, s)\n",
    "                print(f\"[bootstrap] sys.path[0] = {s}\")\n",
    "            return\n",
    "        if p == p.parent: break\n",
    "        p = p.parent\n",
    "    raise ImportError(f\"Couldn't find {src_dir}/{sentinel} above {start}\")\n",
    "\n",
    "add_src_to_sys_path()\n",
    "\n",
    "from framework_utils.color import Color\n",
    "from framework_utils.runtime import show_notebook_env\n",
    "from framework_utils.display import show_df, display_section\n",
    "from framework_utils.config import ProjectConfig\n",
    "from framework_utils.write import TableWriter\n",
    "from framework_utils.table import table_exists\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Target table schemas (comments embedded like Notebook 1)\n",
    "# =====================================================================================\n",
    "CHECKS_LOG_STRUCT = T.StructType([\n",
    "    T.StructField(\"log_id\", T.StringType(), False, {\n",
    "        \"comment\": \"PRIMARY KEY. sha256(table_name, run_config_name, row_snapshot_fingerprint, _errors_fingerprint, _warnings_fingerprint).\"\n",
    "    }),\n",
    "    T.StructField(\"table_name\", T.StringType(), False, {\n",
    "        \"comment\": \"Source table FQN (catalog.schema.table) evaluated by DQX.\"\n",
    "    }),\n",
    "    T.StructField(\"run_config_name\", T.StringType(), False, {\n",
    "        \"comment\": \"Run configuration under which the checks were executed.\"\n",
    "    }),\n",
    "\n",
    "    T.StructField(\"_errors\", T.ArrayType(T.StructType([\n",
    "        T.StructField(\"name\", T.StringType(), True, {\"comment\": \"Rule (check) display name.\"}),\n",
    "        T.StructField(\"message\", T.StringType(), True, {\"comment\": \"Human-friendly message from DQX.\"}),\n",
    "        T.StructField(\"columns\", T.ArrayType(T.StringType()), True, {\"comment\": \"Columns referenced by the rule.\"}),\n",
    "        T.StructField(\"filter\", T.StringType(), True, {\"comment\": \"Predicate applied prior to rule evaluation (if any).\"}),\n",
    "        T.StructField(\"function\", T.StringType(), True, {\"comment\": \"DQX function that produced the issue.\"}),\n",
    "        T.StructField(\"run_time\", T.TimestampType(), True, {\"comment\": \"Per-issue timestamp (if populated by DQX).\"}),\n",
    "        T.StructField(\"user_metadata\", T.MapType(T.StringType(), T.StringType()), True, {\"comment\": \"Free-form metadata map from rule definition.\"}),\n",
    "        T.StructField(\"check_id\", T.StringType(), True, {\"comment\": \"Originating check_id resolved from checks_config.\"}),\n",
    "    ])), False, {\"comment\": \"Array of error issues as emitted by DQX, enriched with check_id.\"}),\n",
    "    T.StructField(\"_errors_fingerprint\", T.StringType(), False, {\n",
    "        \"comment\": \"Deterministic digest of normalized _errors (order-insensitive).\"\n",
    "    }),\n",
    "\n",
    "    T.StructField(\"_warnings\", T.ArrayType(T.StructType([\n",
    "        T.StructField(\"name\", T.StringType(), True, {\"comment\": \"Rule (check) display name.\"}),\n",
    "        T.StructField(\"message\", T.StringType(), True, {\"comment\": \"Human-friendly message from DQX.\"}),\n",
    "        T.StructField(\"columns\", T.ArrayType(T.StringType()), True, {\"comment\": \"Columns referenced by the rule.\"}),\n",
    "        T.StructField(\"filter\", T.StringType(), True, {\"comment\": \"Predicate applied prior to rule evaluation (if any).\"}),\n",
    "        T.StructField(\"function\", T.StringType(), True, {\"comment\": \"DQX function that produced the issue.\"}),\n",
    "        T.StructField(\"run_time\", T.TimestampType(), True, {\"comment\": \"Per-issue timestamp (if populated by DQX).\"}),\n",
    "        T.StructField(\"user_metadata\", T.MapType(T.StringType(), T.StringType()), True, {\"comment\": \"Free-form metadata map from rule definition.\"}),\n",
    "        T.StructField(\"check_id\", T.StringType(), True, {\"comment\": \"Originating check_id resolved from checks_config.\"}),\n",
    "    ])), False, {\"comment\": \"Array of warning issues as emitted by DQX, enriched with check_id.\"}),\n",
    "    T.StructField(\"_warnings_fingerprint\", T.StringType(), False, {\n",
    "        \"comment\": \"Deterministic digest of normalized _warnings (order-insensitive).\"\n",
    "    }),\n",
    "\n",
    "    T.StructField(\"row_snapshot\", T.ArrayType(T.StructType([\n",
    "        T.StructField(\"column\", T.StringType(), False, {\"comment\": \"Column name.\"}),\n",
    "        T.StructField(\"value\", T.StringType(), True, {\"comment\": \"Stringified value at evaluation time.\"}),\n",
    "    ])), False, {\"comment\": \"Snapshot of non-reserved columns for the flagged row.\"}),\n",
    "    T.StructField(\"row_snapshot_fingerprint\", T.StringType(), False, {\n",
    "        \"comment\": \"sha256(JSON(row_snapshot)) used in log_id and de-duplication.\"\n",
    "    }),\n",
    "\n",
    "    T.StructField(\"created_by\", T.StringType(), False, {\"comment\": \"Audit: writer identity.\"}),\n",
    "    T.StructField(\"created_at\", T.TimestampType(), False, {\"comment\": \"Audit: creation timestamp (UTC).\"}),\n",
    "    T.StructField(\"updated_by\", T.StringType(), True, {\"comment\": \"Audit: last updater (nullable).\"}),\n",
    "    T.StructField(\"updated_at\", T.TimestampType(), True, {\"comment\": \"Audit: update timestamp (UTC, nullable).\"}),\n",
    "])\n",
    "\n",
    "CHECKS_LOG_SUMMARY_BY_RULE_STRUCT = T.StructType([\n",
    "    T.StructField(\"run_config_name\", T.StringType(), False, {\"comment\": \"Run configuration name.\"}),\n",
    "    T.StructField(\"table_name\", T.StringType(), False, {\"comment\": \"Source table name.\"}),\n",
    "    T.StructField(\"rule_name\", T.StringType(), False, {\"comment\": \"Rule (check) name being summarized.\"}),\n",
    "    T.StructField(\"severity\", T.StringType(), False, {\"comment\": \"Normalized severity: error | warning.\"}),\n",
    "    T.StructField(\"rows_flagged\", T.LongType(), False, {\"comment\": \"Total rows flagged by this rule within the table.\"}),\n",
    "    T.StructField(\"table_total_rows\", T.LongType(), True, {\"comment\": \"Total rows scanned in the table (nullable if unknown).\"}),\n",
    "    T.StructField(\"pct_of_table_rows\", T.DoubleType(), False, {\"comment\": \"rows_flagged / table_total_rows (0 if unknown).\"}),\n",
    "])\n",
    "\n",
    "CHECKS_LOG_SUMMARY_BY_TABLE_STRUCT = T.StructType([\n",
    "    T.StructField(\"run_config_name\", T.StringType(), False, {\"comment\": \"Run configuration name.\"}),\n",
    "    T.StructField(\"table_name\", T.StringType(), False, {\"comment\": \"Source table name.\"}),\n",
    "    T.StructField(\"table_total_rows\", T.LongType(), False, {\"comment\": \"Total rows scanned.\"}),\n",
    "    T.StructField(\"table_total_error_rows\", T.LongType(), False, {\"comment\": \"Rows with at least one error.\"}),\n",
    "    T.StructField(\"table_total_warning_rows\", T.LongType(), False, {\"comment\": \"Rows with at least one warning.\"}),\n",
    "    T.StructField(\"total_flagged_rows\", T.LongType(), False, {\"comment\": \"Rows with any error or warning.\"}),\n",
    "    T.StructField(\"distinct_rules_fired\", T.IntegerType(), False, {\"comment\": \"Distinct rule names that fired in the table.\"}),\n",
    "])\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Issue shapes / helpers\n",
    "# =====================================================================================\n",
    "DQX_ISSUE_STRUCT = T.StructType([\n",
    "    T.StructField(\"name\", T.StringType(), True),\n",
    "    T.StructField(\"message\", T.StringType(), True),\n",
    "    T.StructField(\"columns\", T.ArrayType(T.StringType()), True),\n",
    "    T.StructField(\"filter\", T.StringType(), True),\n",
    "    T.StructField(\"function\", T.StringType(), True),\n",
    "    T.StructField(\"run_time\", T.TimestampType(), True),\n",
    "    T.StructField(\"user_metadata\", T.MapType(T.StringType(), T.StringType()), True),\n",
    "])\n",
    "DQX_ISSUE_ARRAY = T.ArrayType(DQX_ISSUE_STRUCT)\n",
    "\n",
    "ISSUE_WITH_ID_STRUCT = T.StructType([\n",
    "    T.StructField(\"name\", T.StringType(), True),\n",
    "    T.StructField(\"message\", T.StringType(), True),\n",
    "    T.StructField(\"columns\", T.ArrayType(T.StringType()), True),\n",
    "    T.StructField(\"filter\", T.StringType(), True),\n",
    "    T.StructField(\"function\", T.StringType(), True),\n",
    "    T.StructField(\"run_time\", T.TimestampType(), True),\n",
    "    T.StructField(\"user_metadata\", T.MapType(T.StringType(), T.StringType()), True),\n",
    "    T.StructField(\"check_id\", T.StringType(), True),\n",
    "])\n",
    "ISSUE_WITH_ID_ARRAY = T.ArrayType(ISSUE_WITH_ID_STRUCT)\n",
    "\n",
    "def _empty_raw_issues() -> F.Column:\n",
    "    return F.from_json(F.lit(\"[]\"), DQX_ISSUE_ARRAY)\n",
    "\n",
    "def _empty_with_id_issues() -> F.Column:\n",
    "    return F.from_json(F.lit(\"[]\"), ISSUE_WITH_ID_ARRAY)\n",
    "\n",
    "def _normalize_to_raw_issue_array(col: F.Column) -> F.Column:\n",
    "    js = F.when(col.isNull(), F.lit(\"[]\")).otherwise(F.to_json(col))\n",
    "    return F.coalesce(F.from_json(js, DQX_ISSUE_ARRAY), _empty_raw_issues())\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# JIT argument coercion (same as your working notebook)\n",
    "# =====================================================================================\n",
    "def _parse_scalar(s: Optional[str]):\n",
    "    if s is None: return None\n",
    "    s = s.strip()\n",
    "    sl = s.lower()\n",
    "    if sl in (\"null\", \"none\", \"\"): return None\n",
    "    if sl == \"true\": return True\n",
    "    if sl == \"false\": return False\n",
    "    if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"{\") and s.endswith(\"}\")):\n",
    "        try: return json.loads(s)\n",
    "        except Exception: return s\n",
    "    try:\n",
    "        return int(s) if s.lstrip(\"+-\").isdigit() else float(s)\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "def _to_list(v):\n",
    "    if v is None: return []\n",
    "    if isinstance(v, list): return v\n",
    "    if isinstance(v, str) and v.strip().startswith(\"[\"):\n",
    "        try: return json.loads(v)\n",
    "        except Exception: return [v]\n",
    "    return [v]\n",
    "\n",
    "def _to_num(v):\n",
    "    if v is None: return None\n",
    "    if isinstance(v, (int, float)): return v\n",
    "    try: return int(v) if str(v).lstrip(\"+-\").isdigit() else float(v)\n",
    "    except Exception: return v\n",
    "\n",
    "def _to_bool(v):\n",
    "    if isinstance(v, bool): return v\n",
    "    if isinstance(v, str):\n",
    "        vl = v.strip().lower()\n",
    "        if vl in (\"true\", \"t\", \"1\"): return True\n",
    "        if vl in (\"false\", \"f\", \"0\"): return False\n",
    "    return v\n",
    "\n",
    "def _coerce_arguments(args_map: Optional[Dict[str, str]],\n",
    "                      function_name: Optional[str],\n",
    "                      mode: str = \"permissive\") -> Tuple[Dict[str, Any], List[str]]:\n",
    "    if not args_map: return {}, []\n",
    "    raw = {k:_parse_scalar(v) for k, v in args_map.items()}\n",
    "    spec = _EXPECTED.get((function_name or \"\").strip(), {})\n",
    "\n",
    "    out: Dict[str, Any] = {}\n",
    "    errs: List[str] = []\n",
    "    for k, v in raw.items():\n",
    "        want = spec.get(k)\n",
    "        if want == \"list\":\n",
    "            out[k] = _to_list(v)\n",
    "            if not isinstance(out[k], list):\n",
    "                errs.append(f\"key '{k}' expected list, got {type(out[k]).__name__}\")\n",
    "        elif want == \"num\":\n",
    "            out[k] = _to_num(v)\n",
    "        elif want == \"bool\":\n",
    "            out[k] = _to_bool(v)\n",
    "        elif want == \"str\":\n",
    "            out[k] = \"\" if v is None else str(v)\n",
    "        else:\n",
    "            out[k] = v\n",
    "\n",
    "    if mode == \"strict\" and errs:\n",
    "        raise ValueError(f\"Argument coercion failed for '{function_name}': {errs}\")\n",
    "    return out, errs\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Load checks from table (as dicts, not Rows → avoid .get() on Row)\n",
    "# =====================================================================================\n",
    "def _group_by_table(rules: List[dict]) -> Dict[str, List[dict]]:\n",
    "    out: Dict[str, List[dict]] = {}\n",
    "    for r in rules:\n",
    "        out.setdefault(r[\"table_name\"], []).append(r)\n",
    "    return out\n",
    "\n",
    "def _load_checks_from_table_as_dicts(spark: SparkSession,\n",
    "                                     checks_table: str,\n",
    "                                     run_config_name: str,\n",
    "                                     coercion_mode: str = \"permissive\") -> Tuple[Dict[str, List[dict]], int, int]:\n",
    "    df = (\n",
    "        spark.table(checks_table)\n",
    "        .where((F.col(\"run_config_name\") == run_config_name) & (F.col(\"active\") == True))\n",
    "        .select(\"table_name\", \"name\", \"criticality\", \"filter\",\n",
    "                \"run_config_name\", \"user_metadata\", \"check\")\n",
    "    )\n",
    "    rows = [r.asDict(recursive=True) for r in df.collect()]\n",
    "\n",
    "    raw_rules: List[dict] = []\n",
    "    coerced: int = 0\n",
    "\n",
    "    for r in rows:\n",
    "        chk = r.get(\"check\") or {}\n",
    "        fn  = chk.get(\"function\")\n",
    "        fec = chk.get(\"for_each_column\")\n",
    "        args, _errs = _coerce_arguments(chk.get(\"arguments\"), fn, mode=coercion_mode)\n",
    "        coerced += 1\n",
    "\n",
    "        raw_rules.append({\n",
    "            \"table_name\":       r[\"table_name\"],\n",
    "            \"name\":             r[\"name\"],\n",
    "            \"criticality\":      r[\"criticality\"],\n",
    "            \"run_config_name\":  r[\"run_config_name\"],\n",
    "            \"filter\":           r.get(\"filter\"),\n",
    "            \"user_metadata\":    r.get(\"user_metadata\"),\n",
    "            \"check\": {\n",
    "                \"function\":        fn,\n",
    "                \"for_each_column\": fec if fec else None,\n",
    "                \"arguments\":       args,\n",
    "            },\n",
    "        })\n",
    "\n",
    "    status = DQEngine.validate_checks(raw_rules)\n",
    "    if getattr(status, \"has_errors\", False):\n",
    "        keep: List[dict] = []\n",
    "        skipped: List[str] = []\n",
    "        for r in raw_rules:\n",
    "            st = DQEngine.validate_checks([r])\n",
    "            if getattr(st, \"has_errors\", False):\n",
    "                skipped.append(r.get(\"name\") or \"<unnamed>\")\n",
    "            else:\n",
    "                keep.append(r)\n",
    "        return _group_by_table(keep), coerced, len(skipped)\n",
    "    else:\n",
    "        return _group_by_table(raw_rules), coerced, 0\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Apply checks (isolate bad rules if batch fails)\n",
    "# =====================================================================================\n",
    "def _apply_rules_isolating_failures(dq: DQEngine,\n",
    "                                    src: DataFrame,\n",
    "                                    table_name: str,\n",
    "                                    tbl_rules: List[dict]) -> Tuple[Optional[DataFrame], List[Tuple[str, str]]]:\n",
    "    try:\n",
    "        return dq.apply_checks_by_metadata(src, tbl_rules), []\n",
    "    except Exception:\n",
    "        bad: List[Tuple[str, str]] = []\n",
    "        good: List[dict] = []\n",
    "        for r in tbl_rules:\n",
    "            try:\n",
    "                dq.apply_checks_by_metadata(src, [r])\n",
    "                good.append(r)\n",
    "            except Exception as ex:\n",
    "                bad.append((r.get(\"name\") or \"<unnamed>\", str(ex)))\n",
    "                try:\n",
    "                    print(f\"    offending rule JSON:\\n{json.dumps(r, indent=2)}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        if not good:\n",
    "            return None, bad\n",
    "\n",
    "        try:\n",
    "            return dq.apply_checks_by_metadata(src, good), bad\n",
    "        except Exception as ex2:\n",
    "            print(f\"[{table_name}] still failing after pruning bad rules: {ex2}\")\n",
    "            return None, bad\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Row projection (RAW arrays from DQX)\n",
    "# =====================================================================================\n",
    "def _pick_col(df: DataFrame, *cands: str) -> Optional[str]:\n",
    "    for c in cands:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _normalize_issues_for_fp(arr_col: F.Column) -> F.Column:\n",
    "    # normalize for fingerprint (order-insensitive, sort 'columns'; drop run_time/user_metadata/check_id)\n",
    "    return F.transform(\n",
    "        arr_col,\n",
    "        lambda r: F.struct(\n",
    "            F.lower(F.trim(r[\"name\"])).alias(\"name\"),\n",
    "            F.trim(r[\"message\"]).alias(\"message\"),\n",
    "            F.array_sort(F.transform(F.coalesce(r[\"columns\"], F.array().cast(T.ArrayType(T.StringType()))),\n",
    "                                     lambda c: F.lower(F.trim(c)))).alias(\"columns\"),\n",
    "            F.lower(F.trim(r[\"filter\"])).alias(\"filter\"),\n",
    "            F.lower(F.trim(r[\"function\"])).alias(\"function\"),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def _project_row_hits(df_annot: DataFrame,\n",
    "                      table_name: str,\n",
    "                      run_config_name: str,\n",
    "                      created_by: str,\n",
    "                      exclude_cols: Optional[List[str]] = None) -> DataFrame:\n",
    "    exclude_cols = set(exclude_cols or [])\n",
    "    e_name = _pick_col(df_annot, \"_errors\", \"_error\")\n",
    "    w_name = _pick_col(df_annot, \"_warnings\", \"_warning\")\n",
    "\n",
    "    errs = _normalize_to_raw_issue_array(F.col(e_name) if e_name else F.lit(None))\n",
    "    wrns = _normalize_to_raw_issue_array(F.col(w_name) if w_name else F.lit(None))\n",
    "\n",
    "    df = (df_annot\n",
    "          .withColumn(\"_errs\", errs)\n",
    "          .withColumn(\"_warns\", wrns)\n",
    "          .where((F.size(\"_errs\") > 0) | (F.size(\"_warns\") > 0)))\n",
    "\n",
    "    reserved = {e_name, w_name, \"_errs\", \"_warns\"} - {None} | exclude_cols\n",
    "    cols = [c for c in df.columns if c not in reserved]\n",
    "\n",
    "    row_snapshot = F.array(*[\n",
    "        F.struct(F.lit(c).alias(\"column\"), F.col(c).cast(\"string\").alias(\"value\"))\n",
    "        for c in sorted(cols)\n",
    "    ])\n",
    "    row_snapshot_fp = F.sha2(F.to_json(row_snapshot), 256)\n",
    "\n",
    "    _errors_fp   = F.sha2(F.to_json(F.array_sort(_normalize_issues_for_fp(F.col(\"_errs\")))), 256)\n",
    "    _warnings_fp = F.sha2(F.to_json(F.array_sort(_normalize_issues_for_fp(F.col(\"_warns\")))), 256)\n",
    "\n",
    "    log_id = F.sha2(\n",
    "        F.concat_ws(\"||\", F.lit(table_name), F.lit(run_config_name), row_snapshot_fp, _errors_fp, _warnings_fp),\n",
    "        256\n",
    "    )\n",
    "\n",
    "    return df.select(\n",
    "        log_id.alias(\"log_id\"),\n",
    "        F.lit(table_name).alias(\"table_name\"),\n",
    "        F.lit(run_config_name).alias(\"run_config_name\"),\n",
    "        F.col(\"_errs\").alias(\"_errors\"),     # RAW arrays here (no check_id yet)\n",
    "        _errors_fp.alias(\"_errors_fingerprint\"),\n",
    "        F.col(\"_warns\").alias(\"_warnings\"),  # RAW arrays here (no check_id yet)\n",
    "        _warnings_fp.alias(\"_warnings_fingerprint\"),\n",
    "        row_snapshot.alias(\"row_snapshot\"),\n",
    "        row_snapshot_fp.alias(\"row_snapshot_fingerprint\"),\n",
    "        F.lit(created_by).alias(\"created_by\"),\n",
    "        F.current_timestamp().alias(\"created_at\"),\n",
    "        F.lit(None).cast(T.StringType()).alias(\"updated_by\"),\n",
    "        F.lit(None).cast(T.TimestampType()).alias(\"updated_at\"),\n",
    "    )\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Embed check_id per issue (convert to WITH-ID arrays; JSON trick avoids struct ordering error)\n",
    "# =====================================================================================\n",
    "def _embed_issue_check_ids(row_log_df: DataFrame, checks_table: str) -> DataFrame:\n",
    "    spark = row_log_df.sparkSession\n",
    "\n",
    "    cfg_base = (\n",
    "        spark.table(checks_table)\n",
    "        .where(F.col(\"active\") == True)\n",
    "        .select(\n",
    "            F.lower(F.col(\"table_name\")).alias(\"t_tbl_norm\"),\n",
    "            F.col(\"run_config_name\").alias(\"t_rc\"),\n",
    "            F.lower(F.trim(F.col(\"name\"))).alias(\"t_name_norm\"),\n",
    "            F.lower(F.trim(F.coalesce(F.col(\"filter\"), F.lit(\"\")))).alias(\"t_filter_norm\"),\n",
    "            F.col(\"check_id\").alias(\"cfg_check_id\"),\n",
    "        )\n",
    "        .dropDuplicates([\"t_tbl_norm\",\"t_rc\",\"t_name_norm\",\"t_filter_norm\",\"cfg_check_id\"])\n",
    "    )\n",
    "\n",
    "    cfg_keys = (\n",
    "        cfg_base\n",
    "        .withColumn(\"arr\", F.array(\n",
    "            F.when(F.size(F.split(\"t_tbl_norm\", r\"\\.\")) >= 3, F.concat_ws(\".\", F.element_at(F.split(\"t_tbl_norm\", r\"\\.\"), -3), F.element_at(F.split(\"t_tbl_norm\", r\"\\.\"), -2), F.element_at(F.split(\"t_tbl_norm\", r\"\\.\"), -1))),\n",
    "            F.when(F.size(F.split(\"t_tbl_norm\", r\"\\.\")) >= 2, F.concat_ws(\".\", F.element_at(F.split(\"t_tbl_norm\", r\"\\.\"), -2), F.element_at(F.split(\"t_tbl_norm\", r\"\\.\"), -1))),\n",
    "            F.element_at(F.split(\"t_tbl_norm\", r\"\\.\"), -1)\n",
    "        ))\n",
    "        .withColumn(\"cfg_tbl_key\", F.explode(F.expr(\"filter(arr, x -> x is not null)\")))\n",
    "        .drop(\"arr\")\n",
    "        .dropDuplicates([\"cfg_tbl_key\",\"t_rc\",\"t_name_norm\",\"t_filter_norm\",\"cfg_check_id\"])\n",
    "    )\n",
    "\n",
    "    issue_struct_type = ISSUE_WITH_ID_STRUCT  # reuse exact target type\n",
    "\n",
    "    def enrich(colname: str) -> DataFrame:\n",
    "        log_side = (\n",
    "            row_log_df\n",
    "            .select(\"log_id\", \"table_name\", \"run_config_name\",\n",
    "                    F.posexplode_outer(F.col(colname)).alias(\"pos\", \"iss\"))\n",
    "            .withColumn(\"tbl_norm\", F.lower(F.col(\"table_name\")))\n",
    "            .withColumn(\"rc\", F.col(\"run_config_name\"))\n",
    "            .withColumn(\"name_norm\", F.lower(F.trim(F.col(\"iss.name\"))))\n",
    "            .withColumn(\"filter_norm\", F.lower(F.trim(F.coalesce(F.col(\"iss.filter\"), F.lit(\"\")))))\n",
    "            .withColumn(\"arr\", F.array(\n",
    "                F.when(F.size(F.split(\"tbl_norm\", r\"\\.\")) >= 3, F.concat_ws(\".\", F.element_at(F.split(\"tbl_norm\", r\"\\.\"), -3), F.element_at(F.split(\"tbl_norm\", r\"\\.\"), -2), F.element_at(F.split(\"tbl_norm\", r\"\\.\"), -1))),\n",
    "                F.when(F.size(F.split(\"tbl_norm\", r\"\\.\")) >= 2, F.concat_ws(\".\", F.element_at(F.split(\"tbl_norm\", r\"\\.\"), -2), F.element_at(F.split(\"tbl_norm\", r\"\\.\"), -1))),\n",
    "                F.element_at(F.split(\"tbl_norm\", r\"\\.\"), -1)\n",
    "            ))\n",
    "            .withColumn(\"tbl_key\", F.explode(F.expr(\"filter(arr, x -> x is not null)\")))\n",
    "            .drop(\"arr\")\n",
    "        )\n",
    "\n",
    "        matched = (\n",
    "            log_side.join(\n",
    "                cfg_keys,\n",
    "                (F.col(\"rc\") == F.col(\"t_rc\")) &\n",
    "                (F.col(\"name_norm\") == F.col(\"t_name_norm\")) &\n",
    "                (F.col(\"filter_norm\") == F.col(\"t_filter_norm\")) &\n",
    "                (F.col(\"tbl_key\") == F.col(\"cfg_tbl_key\")),\n",
    "                \"left\"\n",
    "            )\n",
    "            .groupBy(\"log_id\", \"pos\")\n",
    "            .agg(F.first(\"iss\", ignorenulls=True).alias(\"iss\"),\n",
    "                 F.max(\"cfg_check_id\").alias(\"issue_check_id\"))\n",
    "        )\n",
    "\n",
    "        # Build JSON so array_sort compares orderable scalars, not nested structs\n",
    "        matched_json = matched.select(\n",
    "            \"log_id\",\n",
    "            \"pos\",\n",
    "            F.to_json(F.struct(\n",
    "                F.col(\"iss.name\").alias(\"name\"),\n",
    "                F.col(\"iss.message\").alias(\"message\"),\n",
    "                F.col(\"iss.columns\").alias(\"columns\"),\n",
    "                F.col(\"iss.filter\").alias(\"filter\"),\n",
    "                F.col(\"iss.function\").alias(\"function\"),\n",
    "                F.col(\"iss.run_time\").alias(\"run_time\"),\n",
    "                F.col(\"iss.user_metadata\").alias(\"user_metadata\"),\n",
    "                F.col(\"issue_check_id\").cast(T.StringType()).alias(\"check_id\")\n",
    "            )).alias(\"iss_json\")\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            matched_json\n",
    "            .groupBy(\"log_id\")\n",
    "            .agg(F.array_sort(F.collect_list(F.struct(F.col(\"pos\"), F.col(\"iss_json\")))).alias(\"kv\"))\n",
    "            .withColumn(colname, F.transform(F.col(\"kv\"), lambda x: F.from_json(x[\"iss_json\"], issue_struct_type)))\n",
    "            .select(\"log_id\", colname)\n",
    "        )\n",
    "\n",
    "    err_arr = enrich(\"_errors\")\n",
    "    warn_arr = enrich(\"_warnings\")\n",
    "\n",
    "    return (\n",
    "        row_log_df.drop(\"_errors\",\"_warnings\")\n",
    "        .join(err_arr,  \"log_id\", \"left\")\n",
    "        .join(warn_arr, \"log_id\", \"left\")\n",
    "        .withColumn(\"_errors\",   F.coalesce(F.col(\"_errors\"),   _empty_with_id_issues()))\n",
    "        .withColumn(\"_warnings\", F.coalesce(F.col(\"_warnings\"), _empty_with_id_issues()))\n",
    "    )\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Summaries\n",
    "# =====================================================================================\n",
    "def _summarize_table(annot: DataFrame, table_name: str) -> Row:\n",
    "    err = \"_errors\" if \"_errors\" in annot.columns else \"_error\"\n",
    "    wrn = \"_warnings\" if \"_warnings\" in annot.columns else \"_warning\"\n",
    "\n",
    "    annot = annot.cache()\n",
    "    tot = annot.count()\n",
    "    sums = (annot\n",
    "        .select(\n",
    "            (F.size(F.col(err)) > 0).cast(\"int\").alias(\"e\"),\n",
    "            (F.size(F.col(wrn)) > 0).cast(\"int\").alias(\"w\"),\n",
    "            ((F.size(F.col(err)) > 0) | (F.size(F.col(wrn)) > 0)).cast(\"int\").alias(\"f\"),\n",
    "        )\n",
    "        .agg(F.sum(\"e\").alias(\"e\"), F.sum(\"w\").alias(\"w\"), F.sum(\"f\").alias(\"f\"))\n",
    "        .collect()[0]\n",
    "    )\n",
    "    names_arr = F.expr(f\"array_union(transform({err}, x -> x.name), transform({wrn}, x -> x.name))\")\n",
    "    rules = (annot\n",
    "        .select(F.explode_outer(names_arr).alias(\"nm\"))\n",
    "        .where(F.col(\"nm\").isNotNull())\n",
    "        .agg(F.countDistinct(\"nm\").alias(\"rules\"))\n",
    "        .collect()[0][\"rules\"]\n",
    "    )\n",
    "    annot.unpersist()\n",
    "    return Row(\n",
    "        table_name=table_name,\n",
    "        table_total_rows=int(tot),\n",
    "        table_total_error_rows=int(sums[\"e\"]),\n",
    "        table_total_warning_rows=int(sums[\"w\"]),\n",
    "        total_flagged_rows=int(sums[\"f\"]),\n",
    "        distinct_rules_fired=int(rules),\n",
    "    )\n",
    "\n",
    "def _rules_hits_for_table(annot: DataFrame, table_name: str) -> DataFrame:\n",
    "    err = \"_errors\" if \"_errors\" in annot.columns else \"_error\"\n",
    "    wrn = \"_warnings\" if \"_warnings\" in annot.columns else \"_warning\"\n",
    "    errs = (annot.select(F.explode_outer(F.expr(f\"transform({err}, x -> x.name)\")).alias(\"name\"))\n",
    "                  .where(F.col(\"name\").isNotNull()).withColumn(\"severity\", F.lit(\"error\")))\n",
    "    warns = (annot.select(F.explode_outer(F.expr(f\"transform({wrn}, x -> x.name)\")).alias(\"name\"))\n",
    "                   .where(F.col(\"name\").isNotNull()).withColumn(\"severity\", F.lit(\"warning\")))\n",
    "    both = errs.unionByName(warns, allowMissingColumns=True)\n",
    "    return both.groupBy(\"name\",\"severity\").agg(F.count(F.lit(1)).alias(\"rows_flagged\")).withColumn(\"table_name\", F.lit(table_name))\n",
    "\n",
    "\n",
    "# =====================================================================================\n",
    "# Runner\n",
    "# =====================================================================================\n",
    "def run_checks_loader(\n",
    "    spark: SparkSession,\n",
    "    cfg: ProjectConfig,\n",
    "    *,\n",
    "    notebook_idx: int,\n",
    "    exclude_cols: Optional[List[str]] = None,\n",
    "    coercion_mode: str = \"strict\",\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    nb = cfg.notebook(notebook_idx)\n",
    "\n",
    "    checks_table = (\n",
    "        f'{cfg.get(\"notebooks.notebook_1.targets.target_table_1.catalog\")}.'\n",
    "        f'{cfg.get(\"notebooks.notebook_1.targets.target_table_1.schema\")}.'\n",
    "        f'{cfg.get(\"notebooks.notebook_1.targets.target_table_1.table\")}'\n",
    "    )\n",
    "\n",
    "    targets = nb.targets()\n",
    "    t1 = targets.target_table(1)\n",
    "    t2 = targets.target_table(2) if any(str(k).endswith(\"_2\") or str(k) == \"2\" for k in targets.keys()) else None\n",
    "    t3 = targets.target_table(3) if any(str(k).endswith(\"_3\") or str(k) == \"3\" for k in targets.keys()) else None\n",
    "\n",
    "    tw = TableWriter(spark)\n",
    "\n",
    "    # Row log table\n",
    "    results_fqn   = t1.full_table_name()\n",
    "    results_write = t1.get(\"write\") or {}\n",
    "    results_pk    = t1.get(\"primary_key\")\n",
    "    results_part  = t1.get(\"partition_by\") or []\n",
    "    results_desc  = t1.get(\"table_description\")\n",
    "    results_tags  = t1.table_tags()\n",
    "\n",
    "    if not table_exists(spark, results_fqn):\n",
    "        tw.create_table(\n",
    "            fqn=results_fqn,\n",
    "            schema=CHECKS_LOG_STRUCT,\n",
    "            format=results_write.get(\"format\"),\n",
    "            options=results_write.get(\"options\") or {},\n",
    "            partition_by=results_part,\n",
    "            table_comment=results_desc,\n",
    "            table_tags=results_tags,\n",
    "            primary_key_cols=[results_pk] if results_pk else None,\n",
    "            # NOTE: not passing column_comments → same style as Notebook 1 (comments live in schema)\n",
    "        )\n",
    "\n",
    "    # Summary by rule table (optional)\n",
    "    if t2:\n",
    "        s2_fqn    = t2.full_table_name()\n",
    "        t2_write  = t2.get(\"write\") or {}\n",
    "        s2_desc   = t2.get(\"table_description\")\n",
    "        s2_tags   = t2.table_tags()\n",
    "        s2_part   = t2.get(\"partition_by\") or []\n",
    "        if not table_exists(spark, s2_fqn):\n",
    "            tw.create_table(\n",
    "                fqn=s2_fqn,\n",
    "                schema=CHECKS_LOG_SUMMARY_BY_RULE_STRUCT,\n",
    "                format=t2_write.get(\"format\"),\n",
    "                options=t2_write.get(\"options\") or {},\n",
    "                partition_by=s2_part,\n",
    "                table_comment=s2_desc,\n",
    "                table_tags=s2_tags,\n",
    "                primary_key_cols=[t2.get(\"primary_key\")] if t2.get(\"primary_key\") else None,\n",
    "            )\n",
    "\n",
    "    # Summary by table (optional)\n",
    "    if t3:\n",
    "        s3_fqn    = t3.full_table_name()\n",
    "        t3_write  = t3.get(\"write\") or {}\n",
    "        s3_desc   = t3.get(\"table_description\")\n",
    "        s3_tags   = t3.table_tags()\n",
    "        s3_part   = t3.get(\"partition_by\") or []\n",
    "        if not table_exists(spark, s3_fqn):\n",
    "            tw.create_table(\n",
    "                fqn=s3_fqn,\n",
    "                schema=CHECKS_LOG_SUMMARY_BY_TABLE_STRUCT,\n",
    "                format=t3_write.get(\"format\"),\n",
    "                options=t3_write.get(\"options\") or {},\n",
    "                partition_by=s3_part,\n",
    "                table_comment=s3_desc,\n",
    "                table_tags=s3_tags,\n",
    "                primary_key_cols=[t3.get(\"primary_key\")] if t3.get(\"primary_key\") else None,\n",
    "            )\n",
    "\n",
    "    dq = DQEngine(WorkspaceClient())\n",
    "\n",
    "    try:\n",
    "        checks_table_total = spark.table(checks_table).where(F.col(\"active\") == True).count()\n",
    "    except Exception:\n",
    "        checks_table_total = -1\n",
    "\n",
    "    grand_total = 0\n",
    "    all_tbl_summaries: List[Row] = []\n",
    "\n",
    "    # Discover run_config_names from checks table (active only)\n",
    "    rc_names = [r[\"run_config_name\"] for r in (\n",
    "        spark.table(checks_table)\n",
    "        .where(F.col(\"active\") == True)\n",
    "        .select(\"run_config_name\").dropDuplicates().collect()\n",
    "    ) if r[\"run_config_name\"]]\n",
    "\n",
    "    for rc_name in sorted(rc_names):\n",
    "        display_section(f\"Run config: {rc_name}\")\n",
    "\n",
    "        # Load rules (as dicts), JIT coerce args, validate with DQX\n",
    "        by_tbl, coerced, skipped = _load_checks_from_table_as_dicts(\n",
    "            spark, checks_table, rc_name, coercion_mode=coercion_mode\n",
    "        )\n",
    "        checks_loaded = sum(len(v) for v in by_tbl.values())\n",
    "        print(f\"[{rc_name}] checks_in_table_total={checks_table_total}, loaded={checks_loaded}, coerced={coerced}, skipped_invalid={skipped}\")\n",
    "\n",
    "        if not checks_loaded:\n",
    "            print(f\"[{rc_name}] no checks loaded.\")\n",
    "            continue\n",
    "\n",
    "        out_batches: List[DataFrame] = []\n",
    "        rc_tbl_summaries: List[Row] = []\n",
    "        rc_rule_hit_parts: List[DataFrame] = []\n",
    "        table_row_counts: Dict[str, int] = {}\n",
    "        processed_tables: List[str] = []\n",
    "\n",
    "        for tbl, tbl_rules in sorted(by_tbl.items()):\n",
    "            try:\n",
    "                src = spark.read.table(tbl)\n",
    "            except Exception as e:\n",
    "                print(f\"[{rc_name}] {tbl} read failed: {e}\")\n",
    "                continue\n",
    "\n",
    "            annot, bad = _apply_rules_isolating_failures(dq, src, tbl, tbl_rules)\n",
    "            if annot is None:\n",
    "                if bad:\n",
    "                    bad_df = spark.createDataFrame(\n",
    "                        [Row(run_config_name=rc_name,\n",
    "                             table_name=tbl,\n",
    "                             rule_name=nm,\n",
    "                             severity=\"unknown\",\n",
    "                             yaml_path=\"\",\n",
    "                             reason=msg) for nm, msg in bad],\n",
    "                        schema=\"run_config_name string, table_name string, rule_name string, severity string, yaml_path string, reason string\",\n",
    "                    )\n",
    "                    display_section(f\"Skipped rules (apply errors) — run_config={rc_name}, table={tbl}\")\n",
    "                    show_df(bad_df.orderBy(\"rule_name\"), n=1000, truncate=False)\n",
    "                continue\n",
    "\n",
    "            processed_tables.append(tbl)\n",
    "            total_rows = annot.count()\n",
    "            table_row_counts[tbl] = total_rows\n",
    "\n",
    "            summary_row = _summarize_table(annot, tbl)\n",
    "            rc_tbl_summaries.append(summary_row)\n",
    "            all_tbl_summaries.append(Row(run_config_name=rc_name, **summary_row.asDict()))\n",
    "            rc_rule_hit_parts.append(_rules_hits_for_table(annot, tbl))\n",
    "\n",
    "            row_hits = _project_row_hits(annot, tbl, rc_name, created_by=\"AdminUser\", exclude_cols=exclude_cols)\n",
    "            if row_hits.limit(1).count() > 0:\n",
    "                out_batches.append(row_hits)\n",
    "\n",
    "        if rc_tbl_summaries:\n",
    "            summary_df = spark.createDataFrame(rc_tbl_summaries).orderBy(\"table_name\")\n",
    "            display_section(f\"Row-hit summary by table (run_config={rc_name})\")\n",
    "            show_df(summary_df, n=200, truncate=False)\n",
    "\n",
    "        # Summary by rule (optional)\n",
    "        if rc_rule_hit_parts and t2:\n",
    "            summary_by_rule_fqn = t2.full_table_name()\n",
    "            rules_all = reduce(lambda a,b: a.unionByName(b, allowMissingColumns=True), rc_rule_hit_parts)\n",
    "\n",
    "            cfg_rules = (\n",
    "                spark.table(checks_table)\n",
    "                .where((F.col(\"run_config_name\") == rc_name) & (F.col(\"active\") == True))\n",
    "                .where(F.col(\"table_name\").isin(processed_tables))\n",
    "                .select(\n",
    "                    F.col(\"table_name\"),\n",
    "                    F.col(\"name\").alias(\"rule_name\"),\n",
    "                    F.when(F.lower(\"criticality\").isin(\"warn\",\"warning\"), F.lit(\"warning\")).otherwise(F.lit(\"error\")).alias(\"severity\"),\n",
    "                )\n",
    "                .dropDuplicates([\"table_name\",\"rule_name\",\"severity\"])\n",
    "            )\n",
    "\n",
    "            counts = (rules_all.groupBy(\"table_name\",\"name\",\"severity\")\n",
    "                               .agg(F.sum(\"rows_flagged\").alias(\"rows_flagged\"))\n",
    "                               .withColumnRenamed(\"name\",\"rule_name\"))\n",
    "            full_rules = (cfg_rules.join(counts, on=[\"table_name\",\"rule_name\",\"severity\"], how=\"left\")\n",
    "                                   .withColumn(\"rows_flagged\", F.coalesce(F.col(\"rows_flagged\"), F.lit(0))))\n",
    "            totals_df = spark.createDataFrame([Row(table_name=k, table_total_rows=v) for k, v in table_row_counts.items()])\n",
    "            full_rules = (\n",
    "                full_rules.join(totals_df, \"table_name\", \"left\")\n",
    "                .withColumn(\"pct_of_table_rows\",\n",
    "                            F.when(F.col(\"table_total_rows\") > 0,\n",
    "                                   F.col(\"rows_flagged\") / F.col(\"table_total_rows\")).otherwise(F.lit(0.0)))\n",
    "                .select(\"table_name\",\"rule_name\",\"severity\",\"rows_flagged\",\"table_total_rows\",\"pct_of_table_rows\")\n",
    "                .orderBy(F.desc(\"rows_flagged\"), F.asc(\"table_name\"), F.asc(\"rule_name\"))\n",
    "            )\n",
    "            display_section(f\"Row-hit summary by rule (run_config={rc_name})\")\n",
    "            show_df(full_rules, n=2000, truncate=False)\n",
    "\n",
    "            t2_write = t2.get(\"write\") or {}\n",
    "            (full_rules\n",
    "             .withColumn(\"run_config_name\", F.lit(rc_name))\n",
    "             .select(\"run_config_name\",\"table_name\",\"rule_name\",\"severity\",\"rows_flagged\",\"table_total_rows\",\"pct_of_table_rows\")\n",
    "             .write\n",
    "             .format(t2_write.get(\"format\"))\n",
    "             .mode(t2_write.get(\"mode\"))\n",
    "             .options(**(t2_write.get(\"options\") or {}))\n",
    "             .saveAsTable(summary_by_rule_fqn))\n",
    "\n",
    "        # Row-level writes\n",
    "        if not out_batches:\n",
    "            print(f\"[{rc_name}] no row-level hits.\")\n",
    "            continue\n",
    "\n",
    "        out = reduce(lambda a,b: a.unionByName(b, allowMissingColumns=True), out_batches)\n",
    "\n",
    "        # Enrich check_id → WITH-ID arrays\n",
    "        out = _embed_issue_check_ids(out, checks_table)\n",
    "\n",
    "        # Enforce PK idempotency\n",
    "        pk_cols = [t1.get(\"primary_key\")] if isinstance(t1.get(\"primary_key\"), str) else list(t1.get(\"primary_key\"))\n",
    "        dupes = out.groupBy(*pk_cols).count().where(F.col(\"count\") > 1)\n",
    "        if dupes.limit(1).count() > 0:\n",
    "            raise RuntimeError(f\"results batch contains duplicate PKs: {pk_cols}\")\n",
    "        out = out.dropDuplicates(pk_cols)\n",
    "\n",
    "        tw.write_df(\n",
    "            df=out.select(*[f.name for f in CHECKS_LOG_STRUCT.fields]),\n",
    "            fqn=results_fqn,\n",
    "            mode=results_write.get(\"mode\"),\n",
    "            format=results_write.get(\"format\"),\n",
    "            options=results_write.get(\"options\") or {},\n",
    "        )\n",
    "\n",
    "        rows = out.count()\n",
    "        grand_total += rows\n",
    "        print(f\"[{rc_name}] wrote {rows} rows → {results_fqn}\")\n",
    "\n",
    "        # Summary by table (grand)\n",
    "        if t3:\n",
    "            summary_by_table_fqn = t3.full_table_name()\n",
    "            grand_df = (\n",
    "                spark.createDataFrame(all_tbl_summaries)\n",
    "                .select(\"run_config_name\",\"table_name\",\"table_total_rows\",\"table_total_error_rows\",\n",
    "                        \"table_total_warning_rows\",\"total_flagged_rows\",\"distinct_rules_fired\")\n",
    "                .orderBy(\"run_config_name\",\"table_name\")\n",
    "            )\n",
    "            target_schema = spark.table(summary_by_table_fqn).schema\n",
    "            grand_df_aligned = grand_df.select(\n",
    "                *[F.col(f.name).cast(f.dataType).alias(f.name) for f in target_schema.fields]\n",
    "            )\n",
    "            t3_write = t3.get(\"write\") or {}\n",
    "            (grand_df_aligned\n",
    "             .write\n",
    "             .format(t3_write.get(\"format\"))\n",
    "             .mode(t3_write.get(\"mode\"))\n",
    "             .options(**(t3_write.get(\"options\") or {}))\n",
    "             .saveAsTable(summary_by_table_fqn))\n",
    "\n",
    "    display_section(\"Grand total\")\n",
    "    print(f\"{Color.b}{Color.ivory}TOTAL rows written: '{Color.r}{Color.b}{Color.bright_pink}{grand_total}{Color.r}{Color.b}{Color.ivory}'{Color.r}\")\n",
    "\n",
    "    return {\"results_table\": results_fqn, \"grand_total_rows\": grand_total, \"checks_table\": checks_table, \"notebook_idx\": notebook_idx}\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Entrypoint (local/dev)\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    show_notebook_env(spark)\n",
    "    cfg = ProjectConfig(\"resources/dqx_config.yaml\")\n",
    "    result = run_checks_loader(spark=spark, cfg=cfg, notebook_idx=2)\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_run_dqx_checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
